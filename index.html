<!DOCTYPE html>
<html lang="zh" xmlns="">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="stylesheets/index.css"/>
	<link rel="stylesheet" href="stylesheets/mobile.css"/>
	<link rel="stylesheet" href="stylesheets/pc.css"/>
	<title>Kailun Yang 杨恺伦 Personal Web Page</title>
</head>
<body>
<header id="top">
	<div id="top-info">Kailun Yang 杨恺伦</div>
	<span id="top-btn">导航</span>
	<ul id="top-list">
		<li><a href="index.html" class="hover-line">首页 (Index)</a></li>
		<li><a href="gallery.html" class="hover-line">课题组风采 (Gallery)</a></li>
		<li><a href="team.html" class="hover-line">课题组团队 (Team)</a></li>
		<li><a href="#publications" class="hover-line">Publications</a></li>
		<li id="top-list-other"><a href="#" class="hover-line">其他外链 (Link)</a>
			<ul>
				<li><a href="https://scholar.google.com/citations?user=pKFqWhgAAAAJ&hl=en&oi=ao" class="hover-line">Google
					Scholar</a></li>
				<li><a href="https://www.researchgate.net/profile/Kailun_Yang2" class="hover-line">Research Gate</a>
				</li>
				<li><a href="https://dblp.org/pid/190/9526.html" class="hover-line">DBLP</a></li>
			</ul>
		</li>
	</ul>
	<ul id="top-logo">
		<a href="https://robotics.hnu.edu.cn/info/1071/2119.htm">
			<img src="img/hnu.png" alt="HNU"/>
		</a>
		<a href="https://github.com/elnino9ykl">
			<img src="img/github.png" alt="Github"/>
		</a>
	</ul>
</header>

<div class="container">
	<div id="aside">
		<img src="img/ykl.jpg" alt="杨恺伦"/>
		<p>Office 206, Building B3, Fenghuangshan Road 66, Yuelu District, Changsha 410012, Hunan, China.</p>
		<p>Email: <a href="mailto:kailun.yang@hnu.edu.cn">kailun.yang@hnu.edu.cn</a></p>
	</div>

	<div id="main">
		<div id="welcome">
			<h2>Welcome</h2>
			<p>
				I am a Professor at <a href="http://robotics.hnu.edu.cn/">School of Robotics</a> and
				<a href="http://robot.hnu.edu.cn/">National Engineering Research Center of Robot Visual Perception and
					Control
					Technology</a>,
				<a href="http://www-en.hnu.edu.cn/index.htm">Hunan University (HNU)</a>.
				I was a PostDoctoral Researcher at
				<a href="https://cvhci.anthropomatik.kit.edu">Computer Vision for Human-Computer Interaction (CV:HCI)
					Lab</a>,
				Karlsruhe Institute of Technology (KIT), where I worked with
				<a href="https://cvhci.anthropomatik.kit.edu/~stiefel">Prof. Rainer Stiefelhagen</a>.
				I obtained my PhD degree in Information Sensing and Instrumentation Zhejiang University (ZJU).
				My PhD research was jointly advised by <a href="http://wangkaiwei.org">Prof. Kaiwei Wang</a> and
				<a href="https://person.zju.edu.cn/en/baijian">Prof. Jian Bai</a> at
				<a href="http://www.moi-lab.zju.edu.cn/">State Key Laboratory of Modern Optical Instrumentation</a>,
				ZJU, as well as <a href="http://www.robesafe.uah.es/personal/bergasa/">Prof. Luis Miguel Bergasa</a> at
				<a href="https://www.robesafe.uah.es/index.php/en/">Robotics and eSafety (RobeSafe) Research Group</a>,
				University of Alcalá (UAH). Before my PhD, I obtained my dual B.S. degrees in Measurement Technology and
				Instrumentation from Beijing Institute of Technology (BIT) and Economics from Peking University (PKU).
			</p>
			<p>
				杨恺伦，湖南大学机器人学院教授、博士生导师、硕士生导师、入选国家高层次青年人才计划。围绕多模态、高维度、全视角计算光学和计算视觉开展研究，
				以支撑自动驾驶、盲人辅助、四足机器人等应用。2014年6月获北京理工大学测控技术与仪器和北京大学经济学双学位，
				2019年6月获浙江大学测试计量技术及仪器博士学位。2017年9月至2018年9月在西班牙阿尔卡拉大学（UAH）机器人与电子安全（RobeSafe）
				研究组进行博士联合培养。2019年11月至2023年1月在德国卡尔斯鲁厄理工学院（KIT）计算机视觉与人机交互（CV:HCI）实验室开展博士后研究。
				主持国家自然科学基金面上项目、优秀青年科学基金项目（海外）。在IEEE汇刊TPAMI、TIP、TNNLS、T-ITS、TMM、T-ASE、T-IV、TIM、TCI、TAI
				与计算机视觉、机器学习、人工智能、机器人、多媒体顶会CVPR、NeurIPS、ECCV、AAAI、IJCAI、ICRA、IROS、MM等期刊会议上发表论文100余篇，
				入选斯坦福全球前2%顶尖科学家。现拥有及与他人合有专利40余项，4项形成技术转移，获共青团中央举办的“创青春”创新创业大赛全国总冠军。
				担任IEEE T-ITSAE、RA-L AE、Robot Learning AE。获IEEE IV 2021最佳论文奖，ICRA 2024 人机交互最佳论文提名奖。
			</p>
			<p>
				现有若干博士后、博士生、直博生、硕士生、研究助理招生名额。教育最重要的目标莫过于塑造独立之人格、自由之精神，鼓励尝试，宽容失败，
				培养怀有家国情怀、志在改造人生、改造社会、改造世界的知识阶层。深刻地认识到大学教育不仅仅是传授知识，甚至也不止培养能力，
				更为重要的是营造平等的学术氛围并在与同学交互的过程中启发科学思考和科学研究，形成“独立之人格”。课题组注重营造平等的交流与探讨的气氛，
				提倡以co-work的形式相互合作。<a href="team.html">Computer Vision for Panoramic Understanding Lab
				(CV:PU)</a>
				研究小组非常年轻，沟通融洽，除了本小组成员外，还与卡尔斯鲁厄理工学院、浙江大学光电学院、湖南大学机器人学院的其他导师的学生一起共同学习与科研，
				可以充分交叉协作创新。如果您对computer vision, deep learning, scene understanding, autonomous driving感兴趣，
				想到湖南大学机器人学院攻读博士、硕士学位，或者想和我们开展科研合作，请发送邮件到
				<a href="mailto:kailun.yang@hnu.edu.cn">kailun.yang@hnu.edu.cn</a> 。
			</p>
		</div>


		<div id="publications">
			<h2>Publications</h2>
			<ul id="pub-index">
				<li><a href="#preprints">Preprints</a></li>
				<li><a href="#2025">2025</a></li>
				<li><a href="#2024">2024</a></li>
				<li><a href="#2023">2023</a></li>
				<li><a href="#2022">2022</a></li>
				<li><a href="#2021">2021</a></li>
				<li><a href="#2020">2020</a></li>
				<li><a href="#2019">2019</a></li>
				<li><a href="#2018">2018</a></li>
				<li><a href="#2017">2017</a></li>
				<li><a href="#2016">2016</a></li>
				<li><a href="#2015">2015</a></li>
			</ul>

			<h3 id="preprints">Preprints</h3>

			<div class="dashset">
				<div class="dash">
					<img src="./images/arxiv2024_kunyu.jpg" alt="">
					<p>
						K. Peng, D. Wen, S.M. Saquib, Y. Chen, J. Zheng, D. Schneider, <b>K. Yang</b>, J. Wu, A.
						Roitberg,
						R.
						Stiefelhagen.<br>
						<span>Mitigating Label Noise using Prompt-Based Hyperbolic Meta-Learning in Open-Set
					Domain Generalization.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2412.18342">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/HyProMeta">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_siyu.jpg" alt="">
					<p>
						S. Li, <b>K. Yang</b>, H. Shi, S. Wang, Y. Yao, Z. Li.<br>
						<span>GenMapping: Unleashing the Potential of Inverse Perspective Mapping for Robust
					Online HD Map Construction.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2409.08688">[PDF]</a>
						<b><a class="r" href="https://github.com/lynn-yu/GenMapping">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_fan.jpg" alt="">
					<p>
						F. Yang, W. Chen, <b>K. Yang</b>, H. Lin, D. Luo, C. Tang, Z. Li, Y. Wang.<br>
						<span>Learning Granularity-Aware Affordances from Human-Object Interaction for
					Tool-Based Functional Grasping in Dexterous Robotics.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2407.00614.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/yangfan293/GAAF-DEX">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_haosong.jpg" alt="">
					<p>
						H. Shi, S. Wang, J. Zhang, X. Yin, Z. Wang, G. Wang, J. Zhu, <b>K. Yang</b>, K. Wang.<br>
						<span>Offboard Occupancy Refinement with Hybrid Propagation for Autonomous
					Driving.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2403.08504.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/MasterHow/OccFiner">[CODE]</a></b>
					</p>
				</div>


				<div class="dash">
					<img src="./images/arxiv2024_yufan.jpg" alt="">
					<p>
						Y. Zhang, <b>K. Yang</b>, Z. Wang, K. Wang.<br>
						<span>P2U-SLAM: A Monocular Wide-FoV SLAM System Based on Point Uncertainty and Pose
					Uncertainty.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2409.10143">[PDF]</a>
						<b><a class="r" href="https://github.com/BambValley/P2U-SLAM">[CODE]</a></b>
					</p>
				</div>


				<div class="dash">
					<img src="./images/arxiv2024_xiaolongqi.jpg" alt="">
					<p>
						X. Qian, Q. Jiang, Y. Gao, S. Gao, Z. Yi, L. Sun, K. Wei, H. Li, <b>K. Yang</b>, K. Wang, J.
						Bai.<br>
						<span>Towards Single-Lens Controllable Depth-of-Field Imaging via All-in-Focus
					Aberration Correction and Monocular Depth Estimation.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2409.09754">[PDF]</a>
						<b><a class="r" href="https://github.com/XiaolongQian/DCDI">[DATA+CODE]</a></b>
					</p>
				</div>


				<div class="dash">
					<img src="./images/arxiv2024_yao.jpg" alt="">
					<p>
						Y. Gao, Q. Jiang, S. Gao, L. Sun, <b>K. Yang</b>, K. Wang.<br>
						<span>Global Search Optics: Automatically Exploring Optimal Solutions to Compact
					Computational Imaging Systems.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2307.05033.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/wumengshenyou/GSO">[CODE]</a></b>
					</p>
				</div>


				<div class="dash">
					<img src="./images/arxiv2023_xuan.jpg" alt="">
					<p>
						X. He, J. Yuan <b>K. Yang</b>, Z. Zeng, Z. Li.<br>
						<span>S3-MonoDETR: Supervised Shape&amp;Scale-perceptive Deformable Transformer for
					Monocular 3D Object Detection.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2309.00928.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/mikasa3lili/S3-MonoDETR">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_xiaotinghaoyuhan.jpg" alt="">
					<p>
						X. Yin, H. Shi, Y. Bao, Z. Bing, Y. Liao, <b>K. Yang</b>, K. Wang.<br>
						<span>E-3DGS: Gaussian Splatting with Exposure and Motion Events.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2410.16995">[PDF]</a>
						<b><a class="r" href="https://github.com/MasterHow/E-3DGS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_ze.jpg" alt="">
					<p>
						Z. Wang, Y. Li, L. Xu, H. Shi, Z. Ma, Z. Chu, C. Li, F. Gao, <b>K. Yang</b>, K. Wang.<br>
						<span>SF-TIM: A Simple Framework for Enhancing Quadrupedal Robot Jumping Agility by
					Combining Terrain Imagination and Measurement.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2408.00486">[PDF]</a>
						<b><a class="r" href="https://flysoaryun.github.io/SF-TIM">[VIDEO]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2023_yaozuhao.jpg" alt="">
					<p>
						Y. Ye, H. Shi, <b>K. Yang</b>, Z. Wang, X. Yin, Y. Lin, M. Liu, Y. Wang, K. Wang.<br>
						<span>Towards Anytime Optical Flow Estimation with Event Cameras.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2307.05033.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/Yaozhuwa/EVA-Flow">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2023_jiajunjiacheng.jpg" alt="">
					<p>
						J. Chen, J. Lin, Z. Xiao, H. Fu, K. Nai, <b>K. Yang</b>, Z. Li.<br>
						<span>EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring
					Video Object Segmentation.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2308.04162.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/lab206/EPCFormer">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_ruiping.jpg" alt="">
					<p>
						R. Liu, J. Zhang, A. Schön, K. Müller, J. Zheng, <b>K. Yang</b>, K. Gerling, R.
						Stiefelhagen.<br>
						<span>ObjectFinder: Open-Vocabulary Assistive System for Interactive Object Search
					by Blind People.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2412.03118">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_xu.jpg" alt="">
					<p>
						X. Zheng, H. Xue, J. Chen, Y. Yan, L. Jiang, Y. Lyu, <b>K. Yang</b>, L. Zhang, X. Hu.<br>
						<span>Learning Robust Anymodal Segmentor with Unimodal and Cross-modal
					Distillation.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2411.17141">[PDF]</a>
						<b><a class="r" href="https://github.com/zhengxuJosh/AnySeg">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_zhonghua.jpg" alt="">
					<p>
						Z. Yi, H. Shi, Q. Jiang, Y. Gao, Z. Wang, Y. Zhang, <b>K. Yang</b>, K. Wang.<br>
						<span>Benchmarking the Robustness of Optical Flow Estimation to
					Corruptions.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2411.14865">[PDF]</a>
						<b><a class="r"
							  href="https://github.com/ZhonghuaYi/optical_flow_robustness_benchmark">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_qiyao.jpg" alt="">
					<p>
						Q. Jiang, Y. Gao, S. Gao, Z. Yi, L. Sun, H. Shi, <b>K. Yang</b>, K. Wang, J. Bai.<br>
						<span>A Flexible Framework for Universal Computational Aberration Correction via
					Automatic Lens Library Generation and Domain Adaptation.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2409.05809">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2023_yifei.jpg" alt="">
					<p>
						Y. Chen, K. Peng, A. Roitberg, D. Schneider, J. Zhang, J. Zheng, R. Liu, Y. Chen, <b>K. Yang</b>,
						R.
						Stiefelhagen.<br>
						<span>Exploring Self-Supervised Skeleton-Based Human Action Recognition under
					Occlusions.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2309.12029.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/cyfml/OPSTL">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2023_kunyudi.jpg" alt="">
					<p>
						K. Peng, D. Wen, D. Schneider, J. Zhang, <b>K. Yang</b>, M.S. Sarfraz, R. Stiefelhagen, A.
						Roitberg.<br>
						<span>Exploring Few-Shot Adaptation for Activity Recognition on Diverse Domains.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2305.08420.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/RelaMiX">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_haoyuan.jpg" alt="">
					<p>
						H. Li, Q. Hu, Y. Yao, <b>K. Yang</b>, P. Chen.<br>
						<span>CFMW: Cross-modality Fusion Mamba for Multispectral Object Detection under
					Adverse Weather Conditions.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2404.16302.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/lhy-zjut/CFMW">[DATA+CODE]</a></b>
					</p>
				</div>
			</div>

			<h3 id="2025">2025</h3>

			<div class="dashset">
				<div class="dash">
					<img src="./images/wacv2025_zhonghua.jpg" alt="">
					<p>
						Z. Yi, H. Shi, Q. Jiang, <b>K. Yang</b>, Z. Wang, D. Gu, Y. Zhang, K. Wang.<br>
						<span>EI-Nexus: Towards Unmediated and Flexible Inter-Modality Local Feature
					Extraction and Matching for Event-Image Data.</span><br>
						In IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>), Tucson, AZ,
						United
						States,
						February 2025.
						<a class="b" href="https://arxiv.org/pdf/2410.21743">[PDF]</a>
						<b><a class="r" href="https://github.com/ZhonghuaYi/EI-Nexus_official">[DATA+CODE]</a></b>
					</p>
				</div>
			</div>

			<h3 id="2024">2024</h3>

			<div class="dashset">
				<div class="dash">
					<img src="./images/tpami2024_jiaming.jpg" alt="">
					<p>
						J. Zhang, <b>K. Yang</b>, H. Shi, S. Reiß, K. Peng, C. Ma, H. Fu, P.H.S. Torr, K. Wang, R.
						Stiefelhagen.<br>
						<span>Behind Every Domain There is a Shift: Adapting Distortion-aware Vision
					Transformers for Panoramic Semantic Segmentation.</span><br>
						<b>IEEE Transactions on Pattern Analysis and Machine Intelligence</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2207.11860.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/jamycheung/Trans4PASS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tip2024_qishaohua.jpg" alt="">
					<p>
						Q. Jiang, S. Gao, Y. Gao, <b>K. Yang</b>, Z. Yi, H. Shi, L. Sun, K. Wang.<br>
						<span>Minimalist and High-Quality Panoramic Imaging with PSF-aware Transformers.</span><br>
						<b>IEEE Transactions on Image Processing</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2306.12992.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/zju-jiangqi/PCIE-PART">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tip2024_haochengshanjiaming.jpg" alt="">
					<p>
						H. Shi, C. Pang, J. Zhang, <b>K. Yang</b>, Y. Wu, H. Ni, Y. Lin, R. Stiefelhagen, K. Wang.<br>
						<span>CoBEV: Elevating Roadside 3D Object Detection with Depth and Height
					Complementarity.</span><br>
						<b>IEEE Transactions on Image Processing</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2310.02815.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/MasterHow/CoBEV">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tip2024_xu.jpg" alt="">
					<p>
						X. Zhang, <b>K. Yang</b>, J. Lin, J. Yuan, Z. Li, S. Li.<br>
						<span>PVPUFormer: Probabilistic Visual Prompt Unified Transformer for Interactive
					Image Segmentation.</span><br>
						<b>IEEE Transactions on Image Processing</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2306.06656.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/XuZhang1211/PVPUFormer">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tnnls2024_jiacheng.jpg" alt="">
					<p>
						J. Lin, J. Chen, <b>K. Yang</b>, A. Roitberg, S. Li, Z. Li, S. Li.<br>
						<span>AdaptiveClick: Clicks-aware Transformer with Adaptive Focal Loss for
					Interactive Image Segmentation.</span><br>
						<b>IEEE Transactions on Neural Networks and Learning Systems</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2305.04276.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/lab206/AdaptiveClick">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="" alt="">
					<p>

					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2024_ruiping.jpg" alt="">
					<p>
						R. Liu, <b>K. Yang</b>, A. Roitberg, J. Zhang, K. Peng, H. Liu, Y. Wang, R. Stiefelhagen.<br>
						<span>TransKD: Transformer Knowledge Distillation for Efficient Semantic
					Segmentation.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2202.13393.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/RuipingL/TransKD">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2024_siyu.jpg" alt="">
					<p>
						S. Li, J. Lin, H. Shi, J. Zhang, S. Wang, Y. Yao, Z. Li, <b>K. Yang</b>.<br>
						<span>DTCLMapper: Dual Temporal Consistent Learning for Vectorized HD Map
					Construction.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2405.05518.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/lynn-yu/DTCLMapper">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2024_jiachengjiajunkunyu.jpg" alt="">
					<p>
						J. Lin, J. Chen, K. Peng, X. He, Z. Li, R. Stiefelhagen, <b>K. Yang</b>.<br>
						<span>EchoTrack: Auditory Referring Multi-Object Tracking for Autonomous
					Driving.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2402.18302.pdf">[PDF]</a>
						<b><a class="r" href="./videos/echotrack.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/lab206/EchoTrack">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tiv2024_ze.jpg" alt="">
					<p>
						Z. Wang, <b>K. Yang</b>, H. Shi, Y. Zhang, Z. Xu, F. Gao, K. Wang.<br>
						<span>LF-PGVIO: A Visual-Inertial-Odometry Framework for Large Field-of-View Cameras
					using Points and Geodesic Segments.</span><br>
						<b>IEEE Transactions on Intelligent Vehicles</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2306.06663.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/flysoaryun/LF-PGVIO">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tiv2024_haoqi.jpg" alt="">
					<p>
						H. Shi, Q. Jiang, <b>K. Yang</b>, X. Yin, Z. Wang, K. Wang.<br>
						<span>Beyond the Field-of-View: Enhancing Scene Visibility and Perception with
					Clip-Recurrent Transformer.</span><br>
						<b>IEEE Transactions on Intelligent Vehicles</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2211.11293.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/MasterHow/FlowLens">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tiv2024_yihong.jpg" alt="">
					<p>
						Y. Cao, H. Zhang, X. Lu, Z. Xiao, <b>K. Yang</b>, Y. Wang.<br>
						<span>Towards Source-free Domain Adaptive Semantic Segmentation via Importance-aware
					and Prototype-contrast Learning.</span><br>
						<b>IEEE Transactions on Intelligent Vehicles</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2306.01598.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/yihong-97/Source-free_IAPC">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tci2024_qihao.jpg" alt="">
					<p>
						Q. Jiang, H. Shi, S. Gao, J. Zhang, <b>K. Yang</b>, L. Sun, H. Ni, K. Wang.<br>
						<span>Computational Imaging for Machine Perception: Transferring Semantic
					Segmentation beyond Aberrations.</span><br>
						<b>IEEE Transactions on Computational Imaging</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2211.11257.pdf">[PDF]</a>
						<a class="b" href="https://github.com/zju-jiangqi/CIADA">[DATA]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tai2024_feijiaming.jpg" alt="">
					<p>
						F. Teng, J. Zhang, K. Peng, Y. Wang, R. Stiefelhagen, <b>K. Yang</b>.<br>
						<span>OAFuser: Towards Omni-Aperture Fusion for Light Field Semantic
					Segmentation.</span><br>
						<b>IEEE Transactions on Artificial Intelligence</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2307.15588.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/FeiBryantkit/OAFuser">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/cviu2024_xiaotinghaojiaan.jpg" alt="">
					<p>
						X. Yin, H. Shi, J. Chen, Z. Wang, Y. Ye, <b>K. Yang</b>, K. Wang.<br>
						<span>Exploring Event-based Human Pose Estimation with 3D Event Representations.</span><br>
						<b>Computer Vision and Image Understanding</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2311.04591.pdf">[PDF]</a>
						<b><a class="r" href="https://www.youtube.com/watch?v=J8OLkTRSRDM">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/MasterHow/EventPointPose">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/jolt2024_qi.jpg" alt="">
					<p>
						Q. Jiang, Z. Yi, S. Gao, Y. Gao, X. Qian, H. Shi, L. Sun, J. Niu, K. Wang, <b>K. Yang</b>, J.
						Bai.<br>
						<span>Representing Domain-Mixing Optical Degradation for Real-World Computational
					Aberration Correction via Vector Quantization.</span><br>
						<b>Optics &amp; Laser Technology</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2403.10012.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/zju-jiangqi/QDMR">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/jolt2024_shaohua.jpg" alt="">
					<p>
						S. Gao, Q. Jiang, Y. Liao, Y. Qiu, W. Ying, <b>K. Yang</b>, K. Wang, B. Zhang, J. Bai.<br>
						<span>Design, analysis, and manufacturing of a glass-plastic hybrid minimalist
					aspheric panoramic annular lens.</span><br>
						<b>Optics &amp; Laser Technology</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2405.02942.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/neurips2024_kunyu.jpg" alt="">
					<p>
						K. Peng, D. Wen, <b>K. Yang</b>, A. Luo, Y. Chen, J. Fu, M.S. Sarfraz, A. Roitberg, R.
						Stiefelhagen.<br>
						<span>Advancing Open-Set Domain Generalization Using Evidential Bi-Level Hardest
					Domain Schedulers.</span><br>
						In Conference on Neural Information Processing Systems (<b>NeurIPS</b>), Vancouver, Canada,
						December
						2024.
						<a class="b" href="https://arxiv.org/pdf/2409.17555">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/EBiL-HaDS">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icpr2024_feijiaming.jpg" alt="">
					<p>
						F. Teng, J. Zhang, J. Liu, K. Peng, X. Cheng, Z. Li, <b>K. Yang</b>.<br>
						<span>LF Tracy: A Unified Single-Pipeline Approach for Salient Object Detection in
					Light Field Cameras.</span><br>
						In International Conference on Pattern Recognition (<b>ICPR</b>), Kolkata, India, December 2024.
						<a class="b" href="https://arxiv.org/pdf/2401.16712.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/FeiBryantkit/LF-Tracy">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iros2024_yi.jpg" alt="">
					<p>
						Y. Xu, K. Peng, D. Wen, R. Liu, J. Zheng, Y. Chen, J. Zhang, A. Roitberg, <b>K. Yang</b>, R.
						Stiefelhagen.<br>
						<span>Skeleton-Based Human Action Recognition with Noisy Labels.</span><br>
						In IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), Abu Dhabi,
						United
						Arab
						Emirates, October 2024.
						<a class="b" href="https://arxiv.org/pdf/2403.09975.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/xuyizdby/NoiseEraSAR">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/mm2024_kunyu.jpg" alt="">
					<p>
						K. Peng, D. Schneider, A. Roitberg, <b>K. Yang</b>, J. Zhang, C. Deng, K. Zhang, M.S. Sarfraz,
						R.
						Stiefelhagen.<br>
						<span>Towards Activated Muscle Group Estimation in the Wild.</span><br>
						In ACM International Conference on Multimedia (<b>MM</b>), Melbourne, Australia, October 2024.
						<a class="b" href="https://arxiv.org/pdf/2303.00952.pdf">[PDF]</a>
						<b><a class="r" href="https://arxiv.org/pdf/2303.00952.pdf">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/mm2024_kang.jpg" alt="">
					<p>
						K. Zeng, H. Shi, J. Lin, S. Li, J. Cheng, K. Wang, Z. Li, <b>K. Yang</b>.<br>
						<span>MambaMOS: LiDAR-based 3D Moving Object Segmentation with Motion-aware State
					Space Model.</span><br>
						In ACM International Conference on Multimedia (<b>MM</b>), Melbourne, Australia, October 2024.
						<a class="b" href="https://arxiv.org/pdf/2404.12794.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/Terminal-K/MambaMOS">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/smc2024_kai.jpg" alt="">
					<p>
						K. Luo, H. Wu, K. Yi, <b>K. Yang</b>, W. Hao, R. Hu.<br>
						<span>Towards Consistent Object Detection via LiDAR-Camera Synergy.</span><br>
						In IEEE International Conference on Systems, Man, and Cybernetics (<b>SMC</b>), Sarawak,
						Malaysia,
						October
						2024.
						<a class="b" href="https://arxiv.org/pdf/2405.01258.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/xifen523/COD">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/eccv2024_yihongjiaming.jpg" alt="">
					<p>
						Y. Cao, J. Zhang, H. Shi, K. Peng, Y. Zhang, H. Zhang, R. Stiefelhagen, <b>K. Yang</b>.<br>
						<span>Occlusion-Aware Seamless Segmentation.</span><br>
						In European Conference on Computer Vision (<b>ECCV</b>), Milan, Italy, September 2024.
						<a class="b" href="https://arxiv.org/pdf/2407.02182.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/yihong-97/OASS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/eccv2024_kunyujia.jpg" alt="">
					<p>
						K. Peng, J. Fu, <b>K. Yang</b>, D. Wen, Y. Chen, R. Liu, J. Zheng, J. Zhang, M.S. Sarfraz, R.
						Stiefelhagen,
						A. Roitberg.<br>
						<span>Referring Atomic Video Action Recognition.</span><br>
						In European Conference on Computer Vision (<b>ECCV</b>), Milan, Italy, September 2024.
						<a class="b" href="https://arxiv.org/pdf/2407.01872.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/RAVAR">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/eccv2024_junwei.jpg" alt="">
					<p>
						J. Zheng, R. Liu, Y. Chen, K. Peng, C. Wu, <b>K. Yang</b>, J. Zhang, R. Stiefelhagen.<br>
						<span>Open Panoramic Segmentation.</span><br>
						In European Conference on Computer Vision (<b>ECCV</b>), Milan, Italy, September 2024.
						<a class="b" href="https://arxiv.org/pdf/2407.02685.pdf">[PDF]</a>
						<b><a class="r" href="https://junweizheng93.github.io/publications/OPS/OPS.html">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/ijcai2024_song.jpg" alt="">
					<p>
						S. Wang, J. Yu, W. Li, H. Shi, <b>K. Yang</b>, J. Chen, J. Zhu.<br>
						<span>Label-efficient Semantic Scene Completion with Scribble Annotations.</span><br>
						In International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), Jeju, Korea, August
						2024.
						<a class="b" href="https://arxiv.org/pdf/2405.15170.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/songw-zju/Scribble2Scene">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/ijcnn2024_jianbin.jpg" alt="">
					<p>
						J. Jiao, X. Cheng, W. Chen, X. Yin, H. Shi, <b>K. Yang</b>.<br>
						<span>Towards Precise 3D Human Pose Estimation with Multi-Perspective
					Spatial-Temporal Relational Transformers.</span><br>
						In International Joint Conference on Neural Networks (<b>IJCNN</b>), Yokohama, Japan, June 2024.
						<a class="b" href="https://arxiv.org/pdf/2401.16700.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/WUJINHUAN/3D-human-pose">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2024_ruiping.jpg" alt="">
					<p>
						R. Liu, J. Zhang, K. Peng, Y. Chen, K. Cao, J. Zheng, M.S. Sarfraz, <b>K. Yang</b>, R.
						Stiefelhagen.<br>
						<span>Fourier Prompt Tuning for Modality-Incomplete Scene Segmentation.</span><br>
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Jeju Island, Korea, June 2024.
						<a class="b" href="https://arxiv.org/pdf/2401.16923.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/RuipingL/MISS">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icra2024_junweijiaming.jpg" alt="">
					<p>
						J. Zheng, J. Zhang, <b>K. Yang</b>, K. Peng, R. Stiefelhagen.<br>
						<span>MateRobot: Material Recognition in Wearable Robotics for People with Visual
					Impairments.</span><br>
						In IEEE International Conference on Robotics and Automation (<b>ICRA</b>), Yokohama, Japan, May
						2024.
						<b><a style="color:orangered">[Finalist for Best Paper Award on HRI]</a></b>
						<a class="b" href="https://arxiv.org/pdf/2302.14595.pdf">[PDF]</a>
						<b><a class="r" href="./videos/materobot.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/JunweiZheng93/MATERobot">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icassp2024_yiping.jpg" alt="">
					<p>
						Y. Wei, K. Peng, A. Roitberg, J. Zhang, J. Zheng, R. Liu, Y. Chen, <b>K. Yang</b>, R.
						Stiefelhagen.<br>
						<span>Elevating Skeleton-based Action Recognition with Efficient Multi-modality
					Self-supervision.</span><br>
						In IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>),
						Seoul,
						Korea,
						April 2024.
						<a class="b" href="https://arxiv.org/pdf/2309.12009.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/desehuileng0o0/IKEM">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/aaai2024_kunyu.jpg" alt="">
					<p>
						K. Peng, C. Yin, J. Zheng, R. Liu, D. Schneider, J. Zhang, <b>K. Yang</b>, M.S. Sarfraz, R.
						Stiefelhagen, A.
						Roitberg.<br>
						<span>Navigating Open Set Scenarios for Skeleton-based Action Recognition.</span><br>
						In AAAI Conference on Artificial Intelligence (<b>AAAI</b>), Vancouver, Canada, February 2024.
						<a class="b" href="https://arxiv.org/pdf/2312.06330.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/OS-SAR">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/wacv2024_zhifeng.jpg" alt="">
					<p>
						Z. Teng, J. Zhang, <b>K. Yang</b>, K. Peng, H. Shi, S. Reiß, K. Cao, R. Stiefelhagen.<br>
						<span>360BEV: Panoramic Semantic Mapping for Indoor Bird's-Eye View.</span><br>
						In IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>), Waikoloa, HI,
						United
						States,
						January 2024.
						<a class="b" href="https://arxiv.org/pdf/2303.11910.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/jamycheung/360BEV">[DATA+CODE]</a></b>
					</p>
				</div>
			</div>

			<h3 id="2023">2023</h3>

			<div class="dashset">

			</div>

			<div class="dash">
				<img src="" alt="">
				<p>

				</p>
			</div>

			<div class="dash">
				<img src="" alt="">
				<p>

				</p>
			</div>

			<h3 id="2022">2022</h3>
			<h3 id="2021">2021</h3>
			<h3 id="2020">2020</h3>
			<h3 id="2019">2019</h3>
			<h3 id="2018">2018</h3>
			<h3 id="2017">2017</h3>
			<h3 id="2016">2016</h3>
			<h3 id="2015">2015</h3>
		</div>
	</div>
</div>

<script>
	// CSS Navbar 背景色滚动类
	window.addEventListener("scroll", function () {
		const nav = document.getElementById("top");
		if (window.scrollY > 0) {
			nav.classList.add("scrolled");
		} else {
			nav.classList.remove("scrolled");
		}
	});

	// CSS Navbar 点击菜单
	document.getElementById("top-btn").addEventListener("click", function () {
		const nav = document.getElementById("top");
		if (nav.classList.contains("open")) {
			nav.classList.remove("open");
		} else {
			nav.classList.add("open");
		}
	});

	// Publications 部分格式化
	const pubDivs = document.getElementsByClassName("dash");
	for (const originalDiv of pubDivs) {
		const newDiv = originalDiv;
		const textAndLinks = newDiv.querySelector("p").innerHTML;
		newDiv.querySelector("p").innerHTML = textAndLinks
				.replace(/<a style="color:MidnightBlue">(.*?)<\/a>/sg, '<span>$1</span>')
				.replace(/<a style="color:BLUE" href="(.*?)">(.*?)<\/a>/g, '<a class="b" href="$1">$2</a>')
				.replace(/<b><a style="color:orangered" href="(.*?)">(.*?)<\/a><\/b>/g, '<b><a class="r" href="$1">$2</a></b>');

		originalDiv.parentNode.replaceChild(newDiv, originalDiv);
	}
</script>
</body>
</html>