<!DOCTYPE html>
<html lang="zh" xmlns="">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="stylesheets/index.css"/>
	<link rel="stylesheet" href="stylesheets/navbar.css"/>
	<title>Kailun Yang 杨恺伦 Personal Web Page</title>
</head>
<body>
<header id="nav">
	<div id="nav-info">Kailun Yang 杨恺伦</div>
	<span id="nav-btn">导航</span>
	<ul id="nav-list">
		<li><a href="index.html" class="hover-line">首页 (Index)</a></li>
		<li><a href="gallery.html" class="hover-line">课题组风采 (Gallery)</a></li>
		<li><a href="team.html" class="hover-line">课题组团队 (Team)</a></li>
		<li><a href="#publications" class="hover-line">Publications</a></li>
		<li id="nav-list-other"><a href="#" class="hover-line">其他外链 (Links)</a>
			<ul>
				<li><a href="https://www.researchgate.net/profile/Kailun_Yang2" class="hover-line">ResearchGate</a></li>
				<li><a href="https://dblp.org/pid/190/9526.html" class="hover-line">DBLP</a></li>
				<li><a href="https://arxiv.org/a/yang_k_6.html" class="hover-line">arXiv</a></li>
			</ul>
		</li>
	</ul>
	<ul id="nav-logo">
		<a href="https://robotics.hnu.edu.cn/info/1071/2119.htm">
			<img src="img/hnu.png" alt="HNU"/>
		</a>
		<a href="https://github.com/elnino9ykl">
			<img src="img/github.png" alt="Github"/>
		</a>
		<a href="https://scholar.google.com/citations?user=pKFqWhgAAAAJ&hl=en&oi=ao">
			<img src="img/google-scholar.png" alt="Google Scholar"/>
		</a>
	</ul>
</header>

<div class="container">
	<div id="aside">
		<img src="img/ykl.jpg" alt="杨恺伦"/>
		<p>Contact Address:
			<span id="address">Office 206, Building B3, Fenghuangshan Road 66, Yuelu District, Changsha 410012, Hunan, China.<br></span>
			<span id="clickToCopy"><a href="javascript:void(0)">Click to copy</a></span></p>
		<p id="aside-email">Email: <a href="mailto:kailun.yang @hnu.edu.cn">kailun.yang@hnu.edu.cn</a></p>

		<div id="visitor">
			<a href="http://www.clustrmaps.com/map/Yangkailun.com" title="Statistics of visitors to this page">
				<img src="//www.clustrmaps.com/map_v2.png?d=1HPIz7-x0XkWsw6qff3SsNwK9aBDAPDuY_H1C6byU1s" alt=""/>
			</a>
			<br>
			<a href="http://clustrmaps.com/site/1afir">Visitor Traffic</a>
		</div>
	</div>

	<div id="main">
		<div id="welcome">
			<h2>Welcome</h2>
			<p>
				I am a Professor at <a href="http://robotics.hnu.edu.cn/">School of Robotics</a> and
				<a href="http://robot.hnu.edu.cn/">National Engineering Research Center of Robot Visual Perception and
					Control
					Technology</a>,
				<a href="http://www-en.hnu.edu.cn/index.htm">Hunan University (HNU)</a>.
				I was a PostDoctoral Researcher at
				<a href="https://cvhci.anthropomatik.kit.edu">Computer Vision for Human-Computer Interaction (CV:HCI)
					Lab</a>,
				Karlsruhe Institute of Technology (KIT), where I worked with
				<a href="https://cvhci.anthropomatik.kit.edu/~stiefel">Prof. Rainer Stiefelhagen</a>.
				I obtained my PhD degree in Information Sensing and Instrumentation Zhejiang University (ZJU).
				My PhD research was jointly advised by <a href="http://wangkaiwei.org">Prof. Kaiwei Wang</a> and
				<a href="https://person.zju.edu.cn/en/baijian">Prof. Jian Bai</a> at
				<a href="http://www.moi-lab.zju.edu.cn/">State Key Laboratory of Modern Optical Instrumentation</a>,
				ZJU, as well as <a href="http://www.robesafe.uah.es/personal/bergasa/">Prof. Luis Miguel Bergasa</a> at
				<a href="https://www.robesafe.uah.es/index.php/en/">Robotics and eSafety (RobeSafe) Research Group</a>,
				University of Alcalá (UAH). Before my PhD, I obtained my dual B.S. degrees in Measurement Technology and
				Instrumentation from Beijing Institute of Technology (BIT) and Economics from Peking University (PKU).
			</p>
			<p>
				杨恺伦，湖南大学机器人学院教授、博士生导师、硕士生导师、入选国家高层次青年人才计划。围绕多模态、高维度、全视角计算光学和计算视觉开展研究，
				以支撑自动驾驶、盲人辅助、四足机器人等应用。2014年6月获北京理工大学测控技术与仪器和北京大学经济学双学位，
				2019年6月获浙江大学测试计量技术及仪器博士学位。2017年9月至2018年9月在西班牙阿尔卡拉大学（UAH）机器人与电子安全（RobeSafe）
				研究组进行博士联合培养。2019年11月至2023年1月在德国卡尔斯鲁厄理工学院（KIT）计算机视觉与人机交互（CV:HCI）实验室开展博士后研究。
				主持国家自然科学基金面上项目、优秀青年科学基金项目（海外）。在IEEE汇刊TPAMI、TIP、TNNLS、T-ITS、TMM、T-ASE、T-IV、TIM、TCI、TAI
				与计算机视觉、机器学习、人工智能、机器人、多媒体顶会CVPR、NeurIPS、ECCV、AAAI、IJCAI、ICRA、IROS、MM等期刊会议上发表论文100余篇，
				入选斯坦福全球前2%顶尖科学家。现拥有及与他人合有专利40余项，4项形成技术转移，获共青团中央举办的“创青春”创新创业大赛全国总冠军。
				担任IEEE T-ITS AE、RA-L AE、Robot Learning AE。获IEEE IV 2021最佳论文奖，ICRA 2024 人机交互最佳论文提名奖。
			</p>
			<p>
				现有若干博士后、博士生、直博生、硕士生、研究助理招生名额。教育最重要的目标莫过于塑造独立之人格、自由之精神，鼓励尝试，宽容失败，
				培养怀有家国情怀、志在改造人生、改造社会、改造世界的知识阶层。深刻地认识到大学教育不仅仅是传授知识，甚至也不止培养能力，
				更为重要的是营造平等的学术氛围并在与同学交互的过程中启发科学思考和科学研究，形成“独立之人格”。课题组注重营造平等的交流与探讨的气氛，
				提倡以co-work的形式相互合作。<a href="team.html">Computer Vision for Panoramic Understanding Lab (CV:PU)</a>
				研究小组非常年轻，沟通融洽，除了本小组成员外，还与卡尔斯鲁厄理工学院、浙江大学光电学院、湖南大学机器人学院的其他导师的学生一起共同学习与科研，
				可以充分交叉协作创新。如果您对computer vision, deep learning, scene understanding, autonomous driving感兴趣，
				想到湖南大学机器人学院攻读博士、硕士学位，或者想和我们开展科研合作，请发送邮件到
				<a href="mailto:kailun.yang@hnu.edu.cn">kailun.yang@hnu.edu.cn</a> 。
			</p>
		</div>


		<div id="publications">
			<h2>Publications</h2>
			<ul id="pub-index">
				<li><a href="#preprints">Preprints</a></li>
				<li><a href="#2025">2025</a></li>
				<li><a href="#2024">2024</a></li>
				<li><a href="#2023">2023</a></li>
				<li><a href="#2022">2022</a></li>
				<li><a href="#2021">2021</a></li>
				<li><a href="#2020">2020</a></li>
				<li><a href="#2019">2019</a></li>
				<li><a href="#2018">2018</a></li>
				<li><a href="#2017">2017</a></li>
				<li><a href="#2016">2016</a></li>
				<li><a href="#2015">2015</a></li>
			</ul>

			<br>

			<h3 id="preprints">
				Preprints
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">
				<div class="dash">
					<img src="./images/arxiv2024_kunyu.jpg" alt="">
					<p>
						K. Peng, D. Wen, S.M. Saquib, Y. Chen, J. Zheng, D. Schneider, <b>K. Yang</b>, J. Wu, A. Roitberg, R. Stiefelhagen.<br>
						<span>Mitigating Label Noise using Prompt-Based Hyperbolic Meta-Learning in Open-Set Domain Generalization.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2412.18342">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/HyProMeta">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_siyu.jpg" alt="">
					<p>
						S. Li, <b>K. Yang</b>, H. Shi, S. Wang, Y. Yao, Z. Li.<br>
						<span>GenMapping: Unleashing the Potential of Inverse Perspective Mapping for Robust Online HD Map Construction.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2409.08688">[PDF]</a>
						<b><a class="r" href="https://github.com/lynn-yu/GenMapping">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_fan.jpg" alt="">
					<p>
						F. Yang, W. Chen, <b>K. Yang</b>, H. Lin, D. Luo, C. Tang, Z. Li, Y. Wang.<br>
						<span>Learning Granularity-Aware Affordances from Human-Object Interaction for Tool-Based Functional Grasping in Dexterous Robotics.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2407.00614.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/yangfan293/GAAF-DEX">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2025_shangweihao.jpg" alt="">
					<p>
						S. Guo, H. Shi, S. Wang, X. Yin, <b>K. Yang</b>, K. Wang.<br>
						<span>Event-aided Semantic Scene Completion.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2502.02334">[PDF]</a>
						<b><a class="r" href="https://github.com/Pandapan01/EvSSC">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_haosong.jpg" alt="">
					<p>
						H. Shi, S. Wang, J. Zhang, X. Yin, Z. Wang, G. Wang, J. Zhu, <b>K. Yang</b>, K. Wang.<br>
						<span>Offboard Occupancy Refinement with Hybrid Propagation for Autonomous Driving.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2403.08504.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/MasterHow/OccFiner">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2025_jian.jpg" alt="">
					<p>
						J. Sun, W. Sun, G. Zhang, <b>K. Yang</b>, S. Li, X. Meng, N. Deng, C. Tan.<br>
						<span>CT-UIO: Continuous-Time UWB-Inertial-Odometer Localization Using Non-Uniform B-spline with Fewer Anchors.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2502.06287">[PDF]</a>
						<b><a class="r" href="https://github.com/JasonSun623/CT-UIO">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_yufan.jpg" alt="">
					<p>
						Y. Zhang, <b>K. Yang</b>, Z. Wang, K. Wang.<br>
						<span>P2U-SLAM: A Monocular Wide-FoV SLAM System Based on Point Uncertainty and Pose Uncertainty.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2409.10143">[PDF]</a>
						<b><a class="r" href="https://github.com/BambValley/P2U-SLAM">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_haoyuanqi.jpg" alt="">
					<p>
						H. Li, Q. Hu, Y. Yao, <b>K. Yang</b>, P. Chen.<br>
						<span>CFMW: Cross-modality Fusion Mamba for Multispectral Object Detection under Adverse Weather Conditions.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2404.16302.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/lhy-zjut/CFMW">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_yao.jpg" alt="">
					<p>
						Y. Gao, Q. Jiang, S. Gao, L. Sun, <b>K. Yang</b>, K. Wang.<br>
						<span>Global Search Optics: Automatically Exploring Optimal Solutions to Compact Computational Imaging Systems.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2307.05033.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/wumengshenyou/GSO">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2023_xuan.jpg" alt="">
					<p>
						X. He, J. Yuan <b>K. Yang</b>, Z. Zeng, Z. Li.<br>
						<span>S3-MonoDETR: Supervised Shape&amp;Scale-perceptive Deformable Transformer for Monocular 3D Object Detection.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2309.00928.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/mikasa3lili/S3-MonoDETR">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2023_kunyudi.jpg" alt="">
					<p>
						K. Peng, D. Wen, D. Schneider, J. Zhang, <b>K. Yang</b>, M.S. Sarfraz, R. Stiefelhagen, A. Roitberg.<br>
						<span>Exploring Few-Shot Adaptation for Activity Recognition on Diverse Domains.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2305.08420.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/RelaMiX">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_xiaotinghaoyuhan.jpg" alt="">
					<p>
						X. Yin, H. Shi, Y. Bao, Z. Bing, Y. Liao, <b>K. Yang</b>, K. Wang.<br>
						<span>E-3DGS: Gaussian Splatting with Exposure and Motion Events.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2410.16995">[PDF]</a>
						<b><a class="r" href="https://github.com/MasterHow/E-3DGS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2023_yaozuhao.jpg" alt="">
					<p>
						Y. Ye, H. Shi, <b>K. Yang</b>, Z. Wang, X. Yin, Y. Lin, M. Liu, Y. Wang, K. Wang.<br>
						<span>Towards Anytime Optical Flow Estimation with Event Cameras.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2307.05033.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/Yaozhuwa/EVA-Flow">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_ze.jpg" alt="">
					<p>
						Z. Wang, Y. Li, L. Xu, H. Shi, Z. Ma, Z. Chu, C. Li, F. Gao, <b>K. Yang</b>, K. Wang.<br>
						<span>SF-TIM: A Simple Framework for Enhancing Quadrupedal Robot Jumping Agility by Combining Terrain Imagination and Measurement.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2408.00486">[PDF]</a>
						<b><a class="r" href="https://flysoaryun.github.io/SF-TIM">[VIDEO]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_xu.jpg" alt="">
					<p>
						X. Zheng, H. Xue, J. Chen, Y. Yan, L. Jiang, Y. Lyu, <b>K. Yang</b>, L. Zhang, X. Hu.<br>
						<span>Learning Robust Anymodal Segmentor with Unimodal and Cross-modal Distillation.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2411.17141">[PDF]</a>
						<b><a class="r" href="https://github.com/zhengxuJosh/AnySeg">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2023_yifei.jpg" alt="">
					<p>
						Y. Chen, K. Peng, A. Roitberg, D. Schneider, J. Zhang, J. Zheng, R. Liu, Y. Chen, <b>K. Yang</b>, R. Stiefelhagen.<br>
						<span>Exploring Self-Supervised Skeleton-Based Human Action Recognition under Occlusions.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2309.12029.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/cyfml/OPSTL">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_zhonghua.jpg" alt="">
					<p>
						Z. Yi, H. Shi, Q. Jiang, Y. Gao, Z. Wang, Y. Zhang, <b>K. Yang</b>, K. Wang.<br>
						<span>Benchmarking the Robustness of Optical Flow Estimation to Corruptions.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2411.14865">[PDF]</a>
						<b><a class="r"
							  href="https://github.com/ZhonghuaYi/optical_flow_robustness_benchmark">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_qiyao.jpg" alt="">
					<p>
						Q. Jiang, Y. Gao, S. Gao, Z. Yi, L. Sun, H. Shi, <b>K. Yang</b>, K. Wang, J. Bai.<br>
						<span>A Flexible Framework for Universal Computational Aberration Correction via Automatic Lens Library Generation and Domain Adaptation.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2409.05809">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2024_ruiping.jpg" alt="">
					<p>
						R. Liu, J. Zhang, A. Schön, K. Müller, J. Zheng, <b>K. Yang</b>, K. Gerling, R. Stiefelhagen.<br>
						<span>ObjectFinder: Open-Vocabulary Assistive System for Interactive Object Search by Blind People.</span><br>
						<a class="b" href="https://arxiv.org/pdf/2412.03118">[PDF]</a>
					</p>
				</div>
			</div>

			<h3 id="2025">
				2025
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">
				<div class="dash">
					<img src="./images/tci2025_xiaolongqi.jpg" alt="">
					<p>
						X. Qian, Q. Jiang, Y. Gao, S. Gao, Z. Yi, L. Sun, K. Wei, H. Li, <b>K. Yang</b>, K. Wang, J. Bai.<br>
						<span>Towards Single-Lens Controllable Depth-of-Field Imaging via Depth-Aware Point Spread Functions.</span><br>
						<b>IEEE Transactions on Computational Imaging</b>, 2025.
						<a class="b" href="https://arxiv.org/pdf/2409.09754">[PDF]</a>
						<b><a class="r" href="https://github.com/XiaolongQian/DCDI">[DATA+CODE]</a></b>
					</p>
				</div>
	
				<div class="dash">
					<img src="./images/kbs2025_jiajun.jpg" alt="">
					<p>
						J. Chen, J. Lin, G. Zhong, H. Fu, K. Nai, <b>K. Yang</b>, Z. Li.<br>
						<span>Expression Prompt Collaboration Transformer for Universal Referring ideo Object Segmentation.</span><br>
						<b>Knowledge-Based Systems</b>, 2025.
						<a class="b" href="https://arxiv.org/pdf/2308.04162.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/lab206/EPCFormer">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/wacv2025_zhonghua.jpg" alt="">
					<p>
						Z. Yi, H. Shi, Q. Jiang, <b>K. Yang</b>, Z. Wang, D. Gu, Y. Zhang, K. Wang.<br>
						<span>EI-Nexus: Towards Unmediated and Flexible Inter-Modality Local Feature Extraction and Matching for Event-Image Data.</span><br>
						In IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>), Tucson, AZ, United States, February 2025.
						<a class="b" href="https://arxiv.org/pdf/2410.21743">[PDF]</a>
						<b><a class="r" href="https://github.com/ZhonghuaYi/EI-Nexus_official">[DATA+CODE]</a></b>
					</p>
				</div>
			</div>

			<h3 id="2024">
				2024
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">
				<div class="dash">
					<img src="./images/tpami2024_jiaming.jpg" alt="">
					<p>
						J. Zhang, <b>K. Yang</b>, H. Shi, S. Reiß, K. Peng, C. Ma, H. Fu, P.H.S. Torr, K. Wang, R.
						Stiefelhagen.<br>
						<span>Behind Every Domain There is a Shift: Adapting Distortion-aware Vision
					Transformers for Panoramic Semantic Segmentation.</span><br>
						<b>IEEE Transactions on Pattern Analysis and Machine Intelligence</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2207.11860.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/jamycheung/Trans4PASS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tip2024_qishaohua.jpg" alt="">
					<p>
						Q. Jiang, S. Gao, Y. Gao, <b>K. Yang</b>, Z. Yi, H. Shi, L. Sun, K. Wang.<br>
						<span>Minimalist and High-Quality Panoramic Imaging with PSF-aware Transformers.</span><br>
						<b>IEEE Transactions on Image Processing</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2306.12992.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/zju-jiangqi/PCIE-PART">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tip2024_haochengshanjiaming.jpg" alt="">
					<p>
						H. Shi, C. Pang, J. Zhang, <b>K. Yang</b>, Y. Wu, H. Ni, Y. Lin, R. Stiefelhagen, K. Wang.<br>
						<span>CoBEV: Elevating Roadside 3D Object Detection with Depth and Height
					Complementarity.</span><br>
						<b>IEEE Transactions on Image Processing</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2310.02815.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/MasterHow/CoBEV">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tip2024_xu.jpg" alt="">
					<p>
						X. Zhang, <b>K. Yang</b>, J. Lin, J. Yuan, Z. Li, S. Li.<br>
						<span>PVPUFormer: Probabilistic Visual Prompt Unified Transformer for Interactive
					Image Segmentation.</span><br>
						<b>IEEE Transactions on Image Processing</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2306.06656.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/XuZhang1211/PVPUFormer">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tnnls2024_jiacheng.jpg" alt="">
					<p>
						J. Lin, J. Chen, <b>K. Yang</b>, A. Roitberg, S. Li, Z. Li, S. Li.<br>
						<span>AdaptiveClick: Clicks-aware Transformer with Adaptive Focal Loss for
					Interactive Image Segmentation.</span><br>
						<b>IEEE Transactions on Neural Networks and Learning Systems</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2305.04276.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/lab206/AdaptiveClick">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2024_ruiping.jpg" alt="">
					<p>
						R. Liu, <b>K. Yang</b>, A. Roitberg, J. Zhang, K. Peng, H. Liu, Y. Wang, R. Stiefelhagen.<br>
						<span>TransKD: Transformer Knowledge Distillation for Efficient Semantic
					Segmentation.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2202.13393.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/RuipingL/TransKD">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2024_siyu.jpg" alt="">
					<p>
						S. Li, J. Lin, H. Shi, J. Zhang, S. Wang, Y. Yao, Z. Li, <b>K. Yang</b>.<br>
						<span>DTCLMapper: Dual Temporal Consistent Learning for Vectorized HD Map
					Construction.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2405.05518.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/lynn-yu/DTCLMapper">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2024_jiachengjiajunkunyu.jpg" alt="">
					<p>
						J. Lin, J. Chen, K. Peng, X. He, Z. Li, R. Stiefelhagen, <b>K. Yang</b>.<br>
						<span>EchoTrack: Auditory Referring Multi-Object Tracking for Autonomous
					Driving.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2402.18302.pdf">[PDF]</a>
						<b><a class="r" href="./videos/echotrack.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/lab206/EchoTrack">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tiv2024_ze.jpg" alt="">
					<p>
						Z. Wang, <b>K. Yang</b>, H. Shi, Y. Zhang, Z. Xu, F. Gao, K. Wang.<br>
						<span>LF-PGVIO: A Visual-Inertial-Odometry Framework for Large Field-of-View Cameras
					using Points and Geodesic Segments.</span><br>
						<b>IEEE Transactions on Intelligent Vehicles</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2306.06663.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/flysoaryun/LF-PGVIO">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tiv2024_haoqi.jpg" alt="">
					<p>
						H. Shi, Q. Jiang, <b>K. Yang</b>, X. Yin, Z. Wang, K. Wang.<br>
						<span>Beyond the Field-of-View: Enhancing Scene Visibility and Perception with
					Clip-Recurrent Transformer.</span><br>
						<b>IEEE Transactions on Intelligent Vehicles</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2211.11293.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/MasterHow/FlowLens">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tiv2024_yihong.jpg" alt="">
					<p>
						Y. Cao, H. Zhang, X. Lu, Z. Xiao, <b>K. Yang</b>, Y. Wang.<br>
						<span>Towards Source-free Domain Adaptive Semantic Segmentation via Importance-aware
					and Prototype-contrast Learning.</span><br>
						<b>IEEE Transactions on Intelligent Vehicles</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2306.01598.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/yihong-97/Source-free_IAPC">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tci2024_qihao.jpg" alt="">
					<p>
						Q. Jiang, H. Shi, S. Gao, J. Zhang, <b>K. Yang</b>, L. Sun, H. Ni, K. Wang.<br>
						<span>Computational Imaging for Machine Perception: Transferring Semantic
					Segmentation beyond Aberrations.</span><br>
						<b>IEEE Transactions on Computational Imaging</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2211.11257.pdf">[PDF]</a>
						<a class="b" href="https://github.com/zju-jiangqi/CIADA">[DATA]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tai2024_feijiaming.jpg" alt="">
					<p>
						F. Teng, J. Zhang, K. Peng, Y. Wang, R. Stiefelhagen, <b>K. Yang</b>.<br>
						<span>OAFuser: Towards Omni-Aperture Fusion for Light Field Semantic
					Segmentation.</span><br>
						<b>IEEE Transactions on Artificial Intelligence</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2307.15588.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/FeiBryantkit/OAFuser">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/cviu2024_xiaotinghaojiaan.jpg" alt="">
					<p>
						X. Yin, H. Shi, J. Chen, Z. Wang, Y. Ye, <b>K. Yang</b>, K. Wang.<br>
						<span>Exploring Event-based Human Pose Estimation with 3D Event Representations.</span><br>
						<b>Computer Vision and Image Understanding</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2311.04591.pdf">[PDF]</a>
						<b><a class="r" href="https://www.youtube.com/watch?v=J8OLkTRSRDM">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/MasterHow/EventPointPose">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/jolt2024_qi.jpg" alt="">
					<p>
						Q. Jiang, Z. Yi, S. Gao, Y. Gao, X. Qian, H. Shi, L. Sun, J. Niu, K. Wang, <b>K. Yang</b>, J.
						Bai.<br>
						<span>Representing Domain-Mixing Optical Degradation for Real-World Computational
					Aberration Correction via Vector Quantization.</span><br>
						<b>Optics &amp; Laser Technology</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2403.10012.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/zju-jiangqi/QDMR">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/jolt2024_shaohua.jpg" alt="">
					<p>
						S. Gao, Q. Jiang, Y. Liao, Y. Qiu, W. Ying, <b>K. Yang</b>, K. Wang, B. Zhang, J. Bai.<br>
						<span>Design, analysis, and manufacturing of a glass-plastic hybrid minimalist
					aspheric panoramic annular lens.</span><br>
						<b>Optics &amp; Laser Technology</b>, 2024.
						<a class="b" href="https://arxiv.org/pdf/2405.02942.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/neurips2024_kunyu.jpg" alt="">
					<p>
						K. Peng, D. Wen, <b>K. Yang</b>, A. Luo, Y. Chen, J. Fu, M.S. Sarfraz, A. Roitberg, R.
						Stiefelhagen.<br>
						<span>Advancing Open-Set Domain Generalization Using Evidential Bi-Level Hardest
					Domain Schedulers.</span><br>
						In Conference on Neural Information Processing Systems (<b>NeurIPS</b>), Vancouver, Canada,
						December
						2024.
						<a class="b" href="https://arxiv.org/pdf/2409.17555">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/EBiL-HaDS">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icpr2024_feijiaming.jpg" alt="">
					<p>
						F. Teng, J. Zhang, J. Liu, K. Peng, X. Cheng, Z. Li, <b>K. Yang</b>.<br>
						<span>LF Tracy: A Unified Single-Pipeline Approach for Salient Object Detection in
					Light Field Cameras.</span><br>
						In International Conference on Pattern Recognition (<b>ICPR</b>), Kolkata, India, December 2024.
						<a class="b" href="https://arxiv.org/pdf/2401.16712.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/FeiBryantkit/LF-Tracy">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iros2024_yi.jpg" alt="">
					<p>
						Y. Xu, K. Peng, D. Wen, R. Liu, J. Zheng, Y. Chen, J. Zhang, A. Roitberg, <b>K. Yang</b>, R.
						Stiefelhagen.<br>
						<span>Skeleton-Based Human Action Recognition with Noisy Labels.</span><br>
						In IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), Abu Dhabi,
						United
						Arab
						Emirates, October 2024.
						<a class="b" href="https://arxiv.org/pdf/2403.09975.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/xuyizdby/NoiseEraSAR">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/mm2024_kunyu.jpg" alt="">
					<p>
						K. Peng, D. Schneider, A. Roitberg, <b>K. Yang</b>, J. Zhang, C. Deng, K. Zhang, M.S. Sarfraz,
						R.
						Stiefelhagen.<br>
						<span>Towards Activated Muscle Group Estimation in the Wild.</span><br>
						In ACM International Conference on Multimedia (<b>MM</b>), Melbourne, Australia, October 2024.
						<a class="b" href="https://arxiv.org/pdf/2303.00952.pdf">[PDF]</a>
						<b><a class="r" href="https://arxiv.org/pdf/2303.00952.pdf">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/mm2024_kang.jpg" alt="">
					<p>
						K. Zeng, H. Shi, J. Lin, S. Li, J. Cheng, K. Wang, Z. Li, <b>K. Yang</b>.<br>
						<span>MambaMOS: LiDAR-based 3D Moving Object Segmentation with Motion-aware State
					Space Model.</span><br>
						In ACM International Conference on Multimedia (<b>MM</b>), Melbourne, Australia, October 2024.
						<a class="b" href="https://arxiv.org/pdf/2404.12794.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/Terminal-K/MambaMOS">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/smc2024_kai.jpg" alt="">
					<p>
						K. Luo, H. Wu, K. Yi, <b>K. Yang</b>, W. Hao, R. Hu.<br>
						<span>Towards Consistent Object Detection via LiDAR-Camera Synergy.</span><br>
						In IEEE International Conference on Systems, Man, and Cybernetics (<b>SMC</b>), Sarawak,
						Malaysia,
						October
						2024.
						<a class="b" href="https://arxiv.org/pdf/2405.01258.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/xifen523/COD">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/eccv2024_yihongjiaming.jpg" alt="">
					<p>
						Y. Cao, J. Zhang, H. Shi, K. Peng, Y. Zhang, H. Zhang, R. Stiefelhagen, <b>K. Yang</b>.<br>
						<span>Occlusion-Aware Seamless Segmentation.</span><br>
						In European Conference on Computer Vision (<b>ECCV</b>), Milan, Italy, September 2024.
						<a class="b" href="https://arxiv.org/pdf/2407.02182.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/yihong-97/OASS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/eccv2024_kunyujia.jpg" alt="">
					<p>
						K. Peng, J. Fu, <b>K. Yang</b>, D. Wen, Y. Chen, R. Liu, J. Zheng, J. Zhang, M.S. Sarfraz, R.
						Stiefelhagen,
						A. Roitberg.<br>
						<span>Referring Atomic Video Action Recognition.</span><br>
						In European Conference on Computer Vision (<b>ECCV</b>), Milan, Italy, September 2024.
						<a class="b" href="https://arxiv.org/pdf/2407.01872.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/RAVAR">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/eccv2024_junwei.jpg" alt="">
					<p>
						J. Zheng, R. Liu, Y. Chen, K. Peng, C. Wu, <b>K. Yang</b>, J. Zhang, R. Stiefelhagen.<br>
						<span>Open Panoramic Segmentation.</span><br>
						In European Conference on Computer Vision (<b>ECCV</b>), Milan, Italy, September 2024.
						<a class="b" href="https://arxiv.org/pdf/2407.02685.pdf">[PDF]</a>
						<b><a class="r" href="https://junweizheng93.github.io/publications/OPS/OPS.html">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/ijcai2024_song.jpg" alt="">
					<p>
						S. Wang, J. Yu, W. Li, H. Shi, <b>K. Yang</b>, J. Chen, J. Zhu.<br>
						<span>Label-efficient Semantic Scene Completion with Scribble Annotations.</span><br>
						In International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), Jeju, Korea, August
						2024.
						<a class="b" href="https://arxiv.org/pdf/2405.15170.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/songw-zju/Scribble2Scene">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/ijcnn2024_jianbin.jpg" alt="">
					<p>
						J. Jiao, X. Cheng, W. Chen, X. Yin, H. Shi, <b>K. Yang</b>.<br>
						<span>Towards Precise 3D Human Pose Estimation with Multi-Perspective
					Spatial-Temporal Relational Transformers.</span><br>
						In International Joint Conference on Neural Networks (<b>IJCNN</b>), Yokohama, Japan, June 2024.
						<a class="b" href="https://arxiv.org/pdf/2401.16700.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/WUJINHUAN/3D-human-pose">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2024_ruiping.jpg" alt="">
					<p>
						R. Liu, J. Zhang, K. Peng, Y. Chen, K. Cao, J. Zheng, M.S. Sarfraz, <b>K. Yang</b>, R.
						Stiefelhagen.<br>
						<span>Fourier Prompt Tuning for Modality-Incomplete Scene Segmentation.</span><br>
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Jeju Island, Korea, June 2024.
						<a class="b" href="https://arxiv.org/pdf/2401.16923.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/RuipingL/MISS">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icra2024_junweijiaming.jpg" alt="">
					<p>
						J. Zheng, J. Zhang, <b>K. Yang</b>, K. Peng, R. Stiefelhagen.<br>
						<span>MateRobot: Material Recognition in Wearable Robotics for People with Visual
					Impairments.</span><br>
						In IEEE International Conference on Robotics and Automation (<b>ICRA</b>), Yokohama, Japan, May
						2024.
						<b><a style="color:orangered">[Finalist for Best Paper Award on HRI]</a></b>
						<a class="b" href="https://arxiv.org/pdf/2302.14595.pdf">[PDF]</a>
						<b><a class="r" href="./videos/materobot.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/JunweiZheng93/MATERobot">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icassp2024_yiping.jpg" alt="">
					<p>
						Y. Wei, K. Peng, A. Roitberg, J. Zhang, J. Zheng, R. Liu, Y. Chen, <b>K. Yang</b>, R.
						Stiefelhagen.<br>
						<span>Elevating Skeleton-based Action Recognition with Efficient Multi-modality
					Self-supervision.</span><br>
						In IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>),
						Seoul,
						Korea,
						April 2024.
						<a class="b" href="https://arxiv.org/pdf/2309.12009.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/desehuileng0o0/IKEM">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/aaai2024_kunyu.jpg" alt="">
					<p>
						K. Peng, C. Yin, J. Zheng, R. Liu, D. Schneider, J. Zhang, <b>K. Yang</b>, M.S. Sarfraz, R.
						Stiefelhagen, A.
						Roitberg.<br>
						<span>Navigating Open Set Scenarios for Skeleton-based Action Recognition.</span><br>
						In AAAI Conference on Artificial Intelligence (<b>AAAI</b>), Vancouver, Canada, February 2024.
						<a class="b" href="https://arxiv.org/pdf/2312.06330.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/OS-SAR">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/wacv2024_zhifeng.jpg" alt="">
					<p>
						Z. Teng, J. Zhang, <b>K. Yang</b>, K. Peng, H. Shi, S. Reiß, K. Cao, R. Stiefelhagen.<br>
						<span>360BEV: Panoramic Semantic Mapping for Indoor Bird's-Eye View.</span><br>
						In IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>), Waikoloa, HI,
						United
						States,
						January 2024.
						<a class="b" href="https://arxiv.org/pdf/2303.11910.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/jamycheung/360BEV">[DATA+CODE]</a></b>
					</p>
				</div>
			</div>

			<h3 id="2023">
				2023
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">
				<div class="dash">
					<img src="./images/tits2023_jiaminghuayaokailun.jpg" alt="">
					<p>
						J. Zhang, H. Liu, <b>K. Yang</b>, X. Hu, R. Liu, R. Stiefelhagen.<br>
						<span>CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation with
							Transformers.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2023.
						<a class="b" href="https://arxiv.org/pdf/2203.04838.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/huaaaliu/RGBX_Semantic_Segmentation">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2023_alexander.jpg" alt="">
					<p>
						A. Jaus, <b>K. Yang</b>, R. Stiefelhagen.<br>
						<span>Panoramic Panoptic Segmentation: Insights Into Surrounding Parsing
							for Mobile Agents via Unsupervised Contrastive Learning.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2023.
						<a class="b" href="https://arxiv.org/pdf/2206.10711.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/alexanderjaus/PPS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2023_hao.jpg" alt="">
					<p>
						H. Shi, Y. Zhou, <b>K. Yang</b>, X. Yin, Z. Wang, Y. Ye, Z. Yin, S. Meng, P. Li, K. Wang.<br>
						<span>PanoFlow: Learning 360° Optical Flow for Surrounding Temporal
							Understanding.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2023.
						<a class="b" href="https://arxiv.org/pdf/2202.13388.pdf">[PDF]</a>
						<b><a class="r" href="./videos/panoflow.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/MasterHow/PanoFlow">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tmm2023_kunyu.jpg" alt="">
					<p>
						K. Peng, A. Roitberg, <b>K. Yang</b>, J. Zhang, R. Stiefelhagen.<br>
						<span>Delving Deep into One-Shot Skeleton-based Action Recognition with
							Diverse Occlusions.</span><br>
						<b>IEEE Transactions on Multimedia</b>, 2023.
						<a class="b" href="https://arxiv.org/pdf/2202.11423.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/Trans4SOAR">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tase2023_zekailun.jpg" alt="">
					<p>
						Z. Wang, <b>K. Yang</b>, H. Shi, P. Li, F. Gao, J. Bai, K. Wang.<br>
						<span>LF-VISLAM: A SLAM Framework for Large Field-of-View Cameras with
							Negative Imaging Plane on Mobile Agents.</span><br>
						<b>IEEE Transactions on Automation Science and Engineering</b>, 2023.
						<a class="b" href="https://arxiv.org/pdf/2209.05167.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/flysoaryun/LF-SLAM">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tiv2023_zhonghuahao.jpg" alt="">
					<p>
						Z. Yi, H. Shi, <b>K. Yang</b>, Q. Jiang, Y. Ye, Z. Wang, H. Ni, K. Wang.<br>
						<span>FocusFlow: Boosting Key-Points Optical Flow Estimation for
							Autonomous Driving.</span><br>
						<b>IEEE Transactions on Intelligent Vehicles</b>, 2023.
						<a class="b" href="https://arxiv.org/pdf/2308.07104.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/ZhonghuaYi/FocusFlow_official">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tiv2023_xuan.jpg" alt="">
					<p>
						X. He, F. Yang, <b>K. Yang</b>, J. Lin, H. Fu, M. Wang, J. Yuan, Z. Li.<br>
						<span>SSD-MonoDETR: Supervised Scale-aware Deformable Transformer for
							Monocular 3D Object Detection.</span><br>
						<b>IEEE Transactions on Intelligent Vehicles</b>, 2023.
						<a class="b" href="https://arxiv.org/pdf/2305.07270.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/mikasa3lili/SSD-MonoDETR">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/ral2023_siyu.jpg" alt="">
					<p>
						S. Li, <b>K. Yang</b>, H. Shi, J. Zhang, J. Lin, Z. Teng, Z. Li.<br>
						<span>Bi-Mapper: Holistic BEV Semantic Mapping for Autonomous
							Driving.</span><br>
						<b>IEEE Robotics and Automation Letters</b>, 2023.
						<a class="b" href="https://arxiv.org/pdf/2305.04205.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/lynn-yu/Bi-Mapper">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/robio2023_ke.jpg" alt="">
					<p>
						K. Cao, R. Liu, Z. Wang, K. Peng, J. Zhang, J. Zheng, Z. Teng, <b>K. Yang</b>, R.
						Stiefelhagen.<br>
						<span>Tightly-Coupled LiDAR-Visual SLAM Based on Geometric Features for
							Mobile Agents.</span><br>
						In IEEE International Conference on Robotics and Biomimetics (<b>ROBIO</b>), Samui, Thailand,
						December 2023.
						<a class="b" href="https://arxiv.org/pdf/2307.07763.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iccvw2023_ruiping.jpg" alt="">
					<p>
						R. Liu, J. Zhang, K. Peng, J. Zheng, K. Cao, Y. Chen, <b>K. Yang</b>, R. Stiefelhagen.<br>
						<span>Open Scene Understanding: Grounded Situation Recognition Meets
							Segment Anything for Helping People with Visual Impairments.</span><br>
						In International Workshop on Assistive Computer Vision and Robotics (<b>ACVR</b>) with IEEE/CVF
						International Conference on Computer Vision (<b>ICCV</b>), Paris, France, October 2023.
						<a class="b" href="https://arxiv.org/pdf/2307.07757.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/RuipingL/OpenSU">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/mm2023_guojin.jpg" alt="">
					<p>
						G. Zhong, J. Yuan, P. Wang, <b>K. Yang</b>, W. Guan, Z. Li.<br>
						<span>Contrast-augmented Diffusion Model with Fine-grained Sequence
							Alignment for Markup-to-Image Generation.</span><br>
						In ACM International Conference on Multimedia (<b>MM</b>), Ottawa, ON, Canada, October 2023.
						<a class="b" href="https://arxiv.org/pdf/2308.01147.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/zgj77/FSACDM">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/itsc2023_zehao.jpg" alt="">
					<p>
						Z. Shi, H. Shi, <b>K. Yang</b>, Z. Yin, Y. Lin, K. Wang.<br>
						<span>PanoVPR: Towards Unified Perspective-to-Equirectangular Visual
							Place Recognition via Sliding Windows across the Panoramic View.</span><br>
						In IEEE International Conference on Intelligent Transportation Systems (<b>ITSC</b>), Bilbao,
						Spain, September 2023.
						<a class="b" href="https://arxiv.org/pdf/2303.14095.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/zafirshi/PanoVPR">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/cvpr2023_jiamingruiping.jpg" alt="">
					<p>
						J. Zhang, R. Liu, H. Shi, <b>K. Yang</b>, S. Reiß, K. Peng, H. Fu, K. Wang, R.
						Stiefelhagen.<br>
						<span>Delivering Arbitrary-Modal Semantic Segmentation.</span><br>
						In IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Vancouver,
						Canada, June 2023.
						<a class="b" href="https://arxiv.org/pdf/2303.01480.pdf">[PDF]</a>
						<b><a class="r" href="https://www.youtube.com/watch?v=X-VeSLsEToA">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/jamycheung/DELIVER">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/cvprw2023_haoyu.jpg" alt="">
					<p>
						H. Shi, Y. Li, <b>K. Yang</b>, J. Zhang, K. Peng, A. Roitberg, Y. Ye, H. Ni, K. Wang, R.
						Stiefelhagen.<br>
						<span>FishDreamer: Towards Fisheye Semantic Completion via Unified Image
							Outpainting and Segmentation.</span><br>
						In Omnidirectional Computer Vision (<b>OmniCV</b>) Workshop with IEEE/CVF Conference on Computer
						Vision and Pattern Recognition (<b>CVPR</b>), Vancouver, Canada, June 2023.
						<a class="b" href="https://arxiv.org/pdf/2303.13842.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/MasterHow/FishDreamer">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/w4a2023_merlin.jpg" alt="">
					<p>
						M. Knaeble, G. Sailer, Z. Chen, T. Schwarz, <b>K. Yang</b>, M. Nadj, R. Stiefelhagen, A.
						Maedche.<br>
						<span>AutoChemplete - Making Chemical Structural Formulas
							Accessible.</span><br>
						In International Web for All Conference (<b>W4A</b>), Austin, TX, United States, April 2023.
						<a class="b" href="./publications/w4a2023_merlin.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/wacv2023_chang.jpg" alt="">
					<p>
						C. Chen, J. Zhang, <b>K. Yang</b>, K. Peng, R. Stiefelhagen.<br>
						<span>Trans4Map: Revisiting Holistic Bird's-Eye-View Mapping from
							Egocentric Images to Allocentric Semantics with Vision Transformers.</span><br>
						In IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>), Waikoloa, HI,
						United States, January 2023.
						<a class="b" href="https://arxiv.org/pdf/2207.06205.pdf">[PDF]</a>
						<b><a class="r" href="./videos/trans4map.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/jamycheung/Trans4Map">[CODE]</a></b>
					</p>
				</div>

			</div>

			<h3 id="2022">
				2022
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">

				<div class="dash">
					<img src="./images/tits2022_jiaming.jpg" alt="">
					<p>
						J. Zhang, <b>K. Yang</b>, A. Constantinescu, K. Peng, K. Müller, R. Stiefelhagen.<br>
						<span>Trans4Trans: Efficient Transformer for Transparent Object and
							Semantic Scene Segmentation in Real-World Navigation Assistance.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2022.
						<a class="b" href="https://arxiv.org/pdf/2108.09174.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/jamycheung/Trans4Trans">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2022_kunyu.jpg" alt="">
					<p>
						K. Peng, J. Fei, <b>K. Yang</b>, A. Roitberg, J. Zhang, F. Bieder, P. Heidenreich, C. Stiller,
						R. Stiefelhagen.<br>
						<span>MASS: Multi-Attentional Semantic Segmentation of LiDAR Data for
							Dense Top-View Understanding.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2022.
						<a class="b" href="https://arxiv.org/pdf/2107.00346.pdf">[PDF]</a>
						<b><a class="r" href="./videos/mass.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/KPeng9510/MASS">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2022_alina.jpg" alt="">
					<p>
						A. Roitberg, K. Peng, D. Schneider, <b>K. Yang</b>, M. Koulakis, M. Martinez, R.
						Stiefelhagen.<br>
						<span>Is my Model Overconfident? Towards Uncertainty-aware Driver
							Observation with Reliable and Interpretable Confidence Estimates.</span><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2022.
						<a class="b" href="https://arxiv.org/pdf/2204.04674.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tim2022_shaohua.jpg" alt="">
					<p>
						S. Gao, <b>K. Yang</b>, H. Shi, K. Wang, J. Bai.<br>
						<span>Review on Panoramic Imaging and Its Applications in Scene
							Understanding.</span><br>
						<b>IEEE Transactions on Instrumentation and Measurement</b>, 2022.
						<a class="b" href="https://arxiv.org/pdf/2205.05570.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tci2023_qi.jpg" alt="">
					<p>
						Q. Jiang, H. Shi, L. Sun, S. Gao, <b>K. Yang</b>, K. Wang.<br>
						<span>Annular Computational Imaging: Capture Clear Panoramic Images
							through Simple Lens.</span><br>
						<b>IEEE Transactions on Computational Imaging</b>, 2022.
						<a class="b" href="https://arxiv.org/pdf/2206.06070.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/zju-jiangqi/ACI-PI2RNet">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/oe2022_jia.jpg" alt="">
					<p>
						J. Wang, <b>K. Yang</b>, S. Gao, L. Sun, C. Zhu, K. Wang, J. Bai.<br>
						<span>High-performance Panoramic Annular Lens Design for Real-time
							Semantic Segmentation on Aerial Imagery.</span><br>
						<b>Optical Engineering</b>, 2022.
						<a class="b" href="./publications/oe2022_jia.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/downloadeg.html">[DATA]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/accv2022_qing.jpg" alt="">
					<p>
						Q. Wang, J. Zhang, <b>K. Yang</b>, K. Peng, R. Stiefelhagen.<br>
						<span>MatchFormer: Interleaving Attention in Transformers for Feature
							Matching.</span><br>
						In Asian Conference on Computer Vision (<b>ACCV</b>), Macau, China, December 2022.
						<a class="b" href="https://arxiv.org/pdf/2203.09645.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/jamycheung/MatchFormer">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iros2022_ze.jpg" alt="">
					<p>
						Z. Wang, <b>K. Yang</b>, H. Shi, P. Li, F. Gao, K. Wang.<br>
						<span>LF-VIO: A Visual-Inertial-Odometry Framework for Large
							Field-of-View Cameras with Negative Plane.</span><br>
						In IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), Kyoto,
						Japan, October 2022.
						<a class="b" href="https://arxiv.org/pdf/2202.12613.pdf">[PDF]</a>
						<b><a class="r" href="./videos/lfvio.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/flysoaryun/LF-VIO">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iros2022_kunyu.jpg" alt="">
					<p>
						K. Peng, A. Roitberg, <b>K. Yang</b>, J. Zhang, R. Stiefelhagen.<br>
						<span>TransDARC: Transformer-based Driver Activity Recognition with
							Latent Space Feature Calibration.</span><br>
						In IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), Kyoto,
						Japan, October 2022.
						<a class="b" href="https://arxiv.org/pdf/2203.00927.pdf">[PDF]</a>
						<b><a class="r" href="./videos/transdarc.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/KPeng9510/TransDARC">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/eccv2022_lei.jpg" alt="">
					<p>
						L. Sun, C. Sakardis, J. Liang, Q. Jiang, <b>K. Yang</b>, P. Sun, Y. Ye, K. Wang, L. Van
						Gool.<br>
						<span>Event-Based Fusion for Motion Deblurring with Cross-modal
							Attention.</span><br>
						In European Conference on Computer Vision (<b>ECCV</b>), Tel Aviv, Israel, October 2022.
						<b><a style="color:orangered">[Oral]</a></b>
						<a class="b" href="https://arxiv.org/pdf/2112.00167.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/AHupuJR/EFNet">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/eccvw2022_pingcheng.jpg" alt="">
					<p>
						P.-C. Wei, K. Peng, A. Roitberg, <b>K. Yang</b>, J. Zhang, R. Stiefelhagen.<br>
						<span>Multi-modal Depression Estimation based on Sub-attentional
							Fusion.</span><br>
						In International Workshop on Assistive Computer Vision and Robotics (<b>ACVR</b>) with European
						Conference on Computer Vision (<b>ECCV</b>), Tel Aviv, Israel, October 2022.
						<a class="b" href="https://arxiv.org/pdf/2207.06180.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/3dv2022_jiaan.jpg" alt="">
					<p>
						J. Chen, H. Shi, Y. Ye, <b>K. Yang</b>, L. Sun, K. Wang.<br>
						<span>Efficient Human Pose Estimation via 3D Event Point Cloud.</span><br>
						In International Conference on 3D Vision (<b>3DV</b>), Prague, Czechia, September 2022.
						<a class="b" href="https://arxiv.org/pdf/2206.04511.pdf">[PDF]</a>
						<b><a class="r" href="./videos/eventpointpose.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/MasterHow/EventPointPose">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icpr2022_lukas.jpg" alt="">
					<p>
						L. Schölch, J. Steinhäuser, M. Beichter, C. Seibold, <b>K. Yang</b>, M. Knaeble, T. Schwarz, A.
						Maedche, R. Stiefelhagen.<br>
						<span>Towards Automatic Parsing of Structured Visual Content through the
							Use of Synthetic Data.</span><br>
						In International Conference on Pattern Recognition (<b>ICPR</b>), Montréal Québec, Canada,
						August 2022.
						<a class="b" href="https://arxiv.org/pdf/2204.14136.pdf">[PDF]</a>
						<a class="b" href="https://drive.google.com/drive/folders/1SgmUkd5XuZyxsBHZKEUysR-UsLxwdit6">[DATA]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icchp2022_wenyan.jpg" alt="">
					<p>
						W. Ou, J. Zhang, K. Peng, <b>K. Yang</b>, G. Jaworek, K. Müller, R. Stiefelhagen.<br>
						<span>Indoor Navigation Assistance for Visually Impaired People via
							Dynamic SLAM and Panoptic Segmentation with an RGB-D Sensor.</span><br>
						In Joint International Conference on Digital Inclusion, Assistive Technology &amp; Accessibility
						(<b>ICCHP-AAATE</b>), Lecco, Italy, July 2022.
						<a class="b" href="https://arxiv.org/pdf/2204.01154.pdf">[PDF]</a>
						<b><a class="r" href="./videos/dynamic_slam.mp4">[VIDEO]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icchp2022_merlin.jpg" alt="">
					<p>
						M. Knaeble, Z. Chen, T. Schwarz, G. Sailer, <b>K. Yang</b>, R. Stiefelhagen, A. Maedche.<br>
						<span>Accessible Chemical Structural Formulas through Interactive
							Document Labeling.</span><br>
						In Joint International Conference on Digital Inclusion, Assistive Technology &amp; Accessibility
						(<b>ICCHP-AAATE</b>), Lecco, Italy, July 2022.
						<a class="b" href="./publications/icchp2022_merlin.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/cvpr2022_jiaming.jpg" alt="">
					<p>
						J. Zhang, <b>K. Yang</b>, C. Ma, S. Reiß, K. Peng, R. Stiefelhagen.<br>
						<span>Bending Reality: Distortion-aware Transformers for Adapting to
							Panoramic Semantic Segmentation.</span><br>
						In IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), New Orleans,
						LA, United States, June 2022.
						<a class="b" href="https://arxiv.org/pdf/2203.01452.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/jamycheung/Trans4PASS">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2022_hao.jpg" alt="">
					<p>
						H. Shi, Y. Zhou, <b>K. Yang</b>, X. Yin, K. Wang.<br>
						<span>CSFlow: Learning Optical Flow via Cross Strip Correlation for
							Autonomous Driving.</span><br>
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Aachen, Germany, June 2022.
						<b><a style="color:orangered">[Oral]</a></b>
						<a class="b" href="https://arxiv.org/pdf/2202.00909.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/MasterHow/CSFlow">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/cvprw2022_xinyu.jpg" alt="">
					<p>
						X. Luo, J. Zhang, <b>K. Yang</b>, A. Roitberg, K. Peng, R. Stiefelhagen.<br>
						<span>Towards Robust Semantic Segmentation of Accident Scenes via
							Multi-Source Mixed Sampling and Meta-Learning.</span><br>
						In Workshop on Autonomous Driving (<b>WAD</b>) with IEEE/CVF Conference on Computer Vision and
						Pattern Recognition (<b>CVPR</b>), New Orleans, LA, United States, June 2022.
						<a class="b" href="https://arxiv.org/pdf/2203.10395.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/xinyu-laura/MMUDA">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/cvprw2022_kunyu.jpg" alt="">
					<p>
						K. Peng, A. Roitberg, <b>K. Yang</b>, J. Zhang, R. Stiefelhagen.<br>
						<span>Should I take a walk? Estimating Energy Expenditure from Video
							Data.</span><br>
						In International Workshop on Computer Vision for Physiological Measurement (<b>CVPM</b>) with
						IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), New Orleans, LA,
						United States, June 2022.
						<a class="b" href="https://arxiv.org/pdf/2202.00712.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/Vid2Burn">[DATA+CODE]</a></b>
					</p>
				</div>

			</div>

			<h3 id="2021">
				2021
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">

				<div class="dash">
					<img src="./images/tits2021_jiamingchaoxiang.jpg" alt="">
					<p>
						J. Zhang, C. Ma, <b>K. Yang</b>, A. Roitberg, K. Peng, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9599375/">Transfer
							beyond the Field of View: Dense Panoramic Semantic Segmentation via Unsupervised Domain
							Adaptation.</a><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2021.
						<a class="b" href="https://arxiv.org/pdf/2110.11062.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/chma1024/DensePASS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/tits2021_jiaming.jpg" alt="">
					<p>
						J. Zhang, <b>K. Yang</b>, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9658309">Exploring
							Event-driven Dynamic Context for Accident Scene Segmentation.</a><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2021.
						<a class="b" href="https://arxiv.org/pdf/2112.05006.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/jamycheung/ISSAFE">[DATA+CODE]</a></b>
					</p>
				</div>


				<div class="dash">
					<img src="./images/tip2021_kailun.jpg" alt="">
					<p>
						<b>K. Yang</b>, X. Hu, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9321183">Is
							Context-Aware CNN Ready for the Surroundings? Panoramic Semantic Segmentation in the
							Wild.</a><br>
						<b>IEEE Transactions on Image Processing</b>, 2021.
						<a class="b" href="./publications/tip2021_kailun.pdf">[PDF]</a>
						<a class="b" href="https://github.com/elnino9ykl/WildPASS">[DATA]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/oe2021_kaite.jpg" alt="">
					<p>
						K. Xiang, <b>K. Yang</b>, K. Wang.<br>
						<a class="db" href="https://www.osapublishing.org/oe/abstract.cfm?doi=10.1364/OE.416130">Polarization-driven
							Semantic Segmentation via Efficient Attention-bridged Fusion.</a><br>
						<b>Optics Express</b>, 2021.
						<a class="b" href="https://arxiv.org/pdf/2011.13313.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/file/RGB-P-dataset.rar">[DATA]</a>
						<b><a class="r" href="https://github.com/Katexiang/EAFNet">[CODE]</a></b>
					</p>
				</div>


				<div class="dash">
					<img src="./images/ao2021_hao.jpg" alt="">
					<p>
						H. Chen, W. Hu, <b>K. Yang</b>, J. Bai, K. Wang.<br>
						<a class="db" href="https://www.osapublishing.org/ao/abstract.cfm?uri=ao-60-21-6264">Panoramic
							annular
							SLAM with loop closure and global optimization.</a><br>
						<b>Applied Optics</b>, 2021.
						<a class="b" href="https://arxiv.org/pdf/2102.13400.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/ao2021_keyang.jpg" alt="">
					<p>
						K. Zhou, <b>K. Yang</b>, K. Wang.<br>
						<a class="db" href="https://www.osapublishing.org/ao/abstract.cfm?uri=ao-60-26-8188">Panoramic
							Depth
							Estimation via Supervised and Unsupervised Learning in Indoor Scenes.</a><br>
						<b>Applied Optics</b>, 2021.
						<a class="b" href="https://arxiv.org/pdf/2108.08076.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/zzzkkkyyy/PADENet/tree/padenet-v1">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/sensors2021_zihao.jpg" alt="">
					<p>
						Z. Ji, W. Hu, Z. Wang, <b>K. Yang</b>, K. Wang.<br>
						<a class="db" href="https://www.mdpi.com/1424-8220/21/10/3558">Seeing
							through
							Events: Real-Time Moving Object Sonification for Visually Impaired People using
							Event-Based
							Camera.</a><br>
						<b>Sensors</b>, 2021.
						<a class="b" href="https://www.mdpi.com/1424-8220/21/10/3558/pdf">[PDF]</a>
						<b><a class="r" href="./videos/sonification.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/mapleee/dvs-sonification">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/optica2021_hao.jpg" alt="">
					<p>
						H. Chen, <b>K. Yang</b>, W. Hu, J. Bai, K. Wang.<br>
						<a class="db" href="http://www.opticsjournal.net/Articles/Abstract/gxxb/41/22/2215002.cshtml">Semantic
							Visual Odometry based on Panoramic Annular Imaging.</a><br>
						<b>Acta Optica Sinica</b>, 2021.
						<a class="b" href="./publications/acta2021_hao.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/fg2021_kunyu.jpg" alt="">
					<p>
						K. Peng, A. Roitberg, D. Schneider, M. Koulakis, <b>K. Yang</b>, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9666940">Affect-DML:
							Context-Aware One-Shot Recognition of Human Affect using Deep Metric Learning.</a><br>
						In IEEE International Conference on Automatic Face and Gesture Recognition (<b>FG</b>),
						Jodhpur,
						India (Virtual), December 2021.
						<a class="b" href="https://arxiv.org/pdf/2111.15271.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/KPeng9510/Affect-DML">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/robio2021_haobin.jpg" alt="">
					<p>
						H. Tan, C. Chen, X. Luo, J. Zhang, C. Seibold, <b>K. Yang</b>, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9739520">Flying
							Guide
							Dog: Walkable Path Discovery for the Visually Impaired Utilizing Drones and
							Transformer-based Semantic Segmentation.</a><br>
						In IEEE International Conference on Robotics and Biomimetics (<b>ROBIO</b>), Sanya, China,
						December 2021.
						<a class="b" href="https://arxiv.org/pdf/2108.07007.pdf">[PDF]</a>
						<b><a class="r" href="https://youtu.be/lBYnu3mm6pY">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/EckoTan0804/flying-guide-dog">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/robio2021_ran.jpg" alt="">
					<p>
						R. Yan, <b>K. Yang</b>, K. Wang.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9739390">NLFNet:
							Non-Local Fusion Towards Generalized Multimodal Semantic Segmentation across RGB-Depth,
							Polarization, and Thermal Images.</a><br>
						In IEEE International Conference on Robotics and Biomimetics (<b>ROBIO</b>), Sanya, China,
						December 2021.
						<a class="b" href="./publications/robio2021_ran.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iccvw2021_huayao.jpg" alt="">
					<p>
						H. Liu, R. Liu, <b>K. Yang</b>, J. Zhang, K. Peng, R. Stiefelhagen.<br>
						<a class="db"
						   href="https://openaccess.thecvf.com/content/ICCV2021W/ACVR/html/Liu_HIDA_Towards_Holistic_Indoor_Understanding_for_the_Visually_Impaired_via_ICCVW_2021_paper.html">HIDA:
							Towards Holistic Indoor Understanding for the Visually Impaired via Semantic Instance
							Segmentation with a Wearable Solid-State LiDAR Sensor.</a><br>
						In International Workshop on Assistive Computer Vision and Robotics (<b>ACVR</b>) with
						IEEE/CVF
						International Conference on Computer Vision (<b>ICCV</b>), Montreal, Canada (Virtual),
						October
						2021.
						<a class="b" href="https://arxiv.org/pdf/2107.03180.pdf">[PDF]</a>
						<b><a class="r" href="./videos/hida.mp4">[VIDEO]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iccvw2021_jiaming.jpg" alt="">
					<p>
						J. Zhang, <b>K. Yang</b>, A. Constantinescu, K. Peng, K. Müller, R. Stiefelhagen.<br>
						<a class="db"
						   href="https://openaccess.thecvf.com/content/ICCV2021W/ACVR/html/Zhang_Trans4Trans_Efficient_Transformer_for_Transparent_Object_Segmentation_To_Help_Visually_ICCVW_2021_paper.html">Trans4Trans:
							Efficient Transformer for Transparent Object Segmentation to Help Visually Impaired
							People
							Navigate in the Real World.</a><br>
						In International Workshop on Assistive Computer Vision and Robotics (<b>ACVR</b>) with
						IEEE/CVF
						International Conference on Computer Vision (<b>ICCV</b>), Montreal, Canada (Virtual),
						October
						2021.
						<a class="b" href="https://arxiv.org/pdf/2107.03172.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/jamycheung/Trans4Trans">[CODE]</a></b>
						<a class="b" href="https://www.unite.ai/mapping-out-paths-for-the-blind-with-machine-learning/">[UNITE.AI]</a>
						<a style="color:BLUE"
						   href="https://thegoodai.co/2021/07/12/mapping-out-paths-for-the-blind-with-machine-learning/">[The
							Good AI]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iros2021_jiaming.jpg" alt="">
					<p>
						J. Zhang, <b>K. Yang</b>, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9636109">ISSAFE:
							Improving Semantic Segmentation in Accidents by Fusing Event-based Data.</a><br>
						In IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>),
						Prague,
						Czech Republic (Virtual), September 2021.
						<a class="b" href="https://arxiv.org/pdf/2008.08974.pdf">[PDF]</a>
						<b><a class="r" href="./videos/issafe.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/jamycheung/ISSAFE">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/itsc2021_chaoxiang.jpg" alt="">
					<p>
						C. Ma, J. Zhang, <b>K. Yang</b>, A. Roitberg, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9564920">DensePASS:
							Dense Panoramic Semantic Segmentation via Unsupervised Domain Adaptation with
							Attention-Augmented Context Exchange.</a><br>
						In IEEE International Conference on Intelligent Transportation Systems (<b>ITSC</b>),
						Indianapolis, IN, United States (Virtual), September 2021.
						<a class="b" href="https://arxiv.org/pdf/2108.06383.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/chma1024/DensePASS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/ecmr2021_lei.jpg" alt="">
					<p>
						L. Sun, J. Wang, <b>K. Yang</b>, K. Wu, X. Zhou, K. Wang, J. Bai.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9568802/">Aerial-PASS:
							Panoramic Annular Scene Segmentation in Drone Videos.</a><br>
						In European Conference on Mobile Robots (<b>ECMR</b>), Bonn, Germany (Virtual), August 2021.
						<a class="b" href="https://arxiv.org/pdf/2105.07209.pdf">[PDF]</a>
						<b><a class="r" href="https://ecmr2021.org/wp-content/uploads/2021/09/202109021632_Lei_Sun.mp4">[VIDEO]</a></b>
						<a class="b" href="http://wangkaiwei.org/downloadeg.html">[DATA]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2021_alexander.jpg" alt="">
					<p>
						A. Jaus, <b>K. Yang</b>, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9575904">Panoramic
							Panoptic Segmentation: Towards Complete Surrounding Understanding via Unsupervised
							Contrastive Learning.</a><br>
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Nagoya, Japan (Virtual), July 2021.
						<b><a href="https://cvhci.anthropomatik.kit.edu/img/IV2021-1%20Kopie_rdax_1024x572_98.png"
							  style="color:orangered">[Best Paper Award]</a></b>
						<a class="b" href="https://arxiv.org/pdf/2103.00868.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/alexanderjaus/PPS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2021_shuo.jpg" alt="">
					<p>
						S. Chen, <b>K. Yang</b>, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9575362">DR-TANet:
							Dynamic Receptive Temporal Attention Network for Street Scene Change
							Detection.</a><br>
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Nagoya, Japan (Virtual), July 2021.
						<a class="b" href="https://arxiv.org/pdf/2103.00879.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/Herrccc/DR-TANet">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/rcar2021_wei.jpg" alt="">
					<p>
						W. Mao, J. Zhang, <b>K. Yang</b>, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9517615/">Panoptic
							Lintention Network: Towards Efficient Navigational Perception for the Visually
							Impaired.</a><br>
						In IEEE International Conference on Real-time Computing and Robotics (<b>RCAR</b>), Xining,
						China, July 2021.
						<a class="b" href="https://arxiv.org/pdf/2103.04128.pdf">[PDF]</a>
						<b><a class="r" href="./videos/lintention.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/Wei-Mao/Panoptic-Lintention-Net">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/rcar2021_yingzhi.jpg" alt="">
					<p>
						Y. Zhang, H. Chen, <b>K. Yang</b>, J. Zhang, R. Stiefelhagen.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/9517086/">Perception
							Framework through Real-Time Semantic Segmentation and Scene Recognition on a Wearable
							System
							for the Visually Impaired.</a><br>
						In IEEE International Conference on Real-time Computing and Robotics (<b>RCAR</b>), Xining,
						China, July 2021.
						<a class="b" href="https://arxiv.org/pdf/2103.04136.pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/cvpr2021_kailun.jpg" alt="">
					<p>
						<b>K. Yang</b>, J. Zhang, S. Reiß, X. Hu, R. Stiefelhagen.<br>
						<a class="db"
						   href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Capturing_Omni-Range_Context_for_Omnidirectional_Segmentation_CVPR_2021_paper.html">Capturing
							Omni-Range Context for Omnidirectional Segmentation.</a><br>
						In IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), Nashville,
						TN,
						United States (Virtual), June 2021.
						<a class="b" href="https://arxiv.org/pdf/2103.05687.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/elnino9ykl/WildPASS">[DATA+CODE]</a></b>
						<a class="b" href="https://zhuanlan.zhihu.com/p/360861869">[Zhihu]</a>
						<a class="b" href="https://mp.weixin.qq.com/s/RJLw1JjrylKtOtBAK1Y7vg">[WeChat]</a>
					</p>
				</div>

			</div>

			<h3 id="2020">
				2020
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">

				<div class="dash">
					<img src="./images/tits2020_kailun.jpg" alt="">
					<p>
						<b>K. Yang</b>, X. Hu, Y. Fang, K. Wang, R. Stiefelhagen.<br />
						<a class="db" href="hhttps://ieeexplore.ieee.org/document/9204767">Omnisupervised Omnidirectional Semantic Segmentation.</a><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2020.
						<a class="b" href="./publications/tits2020_kailun.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/elnino9ykl/OOSS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/ral2020_lei.jpg" alt="">
					<p>
						L. Sun, <b>K. Yang</b>, X. Hu, W. Hu, K. Wang.<br />
						<a class="db" href="https://ieeexplore.ieee.org/document/9134735">Real-time Fusion Network for RGB-D Semantic Segmentation Incorporating Unexpected Obstacle Detection for Road-driving Images.</a><br />
						<b>IEEE Robotics and Automation Letters</b> with IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), Las Vegas, NV, United States (Virtual), October 2020.
						<a class="b" href="http://wangkaiwei.org/file/publications/ral2020_lei.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/AHupuJR/RFNet">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/sensors2020_manuel.jpg" alt="">
					<p>
						M. Martinez, <b>K. Yang</b>, A. Constantinescu, R. Stiefelhagen.<br />
						<a class="db" href="https://www.mdpi.com/1424-8220/20/18/5202">Helping the Blind to Get through COVID-19: Social Distancing Assistant Using Real-Time Semantic Segmentation on RGB-D Video.</a><br />
						<b>Sensors</b>, 2020.
						<b><a style="color:orangered">[Highlighted as an Editors' Pick]</a></b>
						<a class="b" href="https://www.mdpi.com/1424-8220/20/18/5202/pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/elnino9ykl/DS-PASS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/sensors2020_weijian.jpg" alt="">
					<p>
						W. Hu, K. Wang, <b>K. Yang</b>, R. Cheng, Y. Ye, L. Sun, Z. Xu.<br />
						<a class="db" href="https://www.mdpi.com/1424-8220/20/11/3222">A Comparative Study in Real-Time Scene Sonification for Visually Impaired People.</a><br />
						<b>Sensors</b>, 2020.
						<a class="b" href="https://www.mdpi.com/1424-8220/20/11/3222/pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/sensors2020_yicheng.jpg" alt="">
					<p>
						Y. Fang, <b>K. Yang</b>, R. Cheng, L. Sun, K. Wang.<br />
						<a class="db" href="https://www.mdpi.com/1424-8220/20/15/4177">A Panoramic Localizer Based on Coarse-to-Fine Descriptors for Navigation Assistance.</a><br />
						<b>Sensors</b>, 2020.
						<a class="b" href="https://www.mdpi.com/1424-8220/20/15/4177/pdf">[PDF]</a>
						<a class="b" href="https://github.com/dachengzihhh/Chengyuan-dataset">[DATA]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/arxiv2020_wei.jpg" alt="">
					<p>
						W. Mao, J. Zhang, <b>K. Yang</b>, R. Stiefelhagen.<br />
						<a class="db" href="https://arxiv.org/abs/2007.10202">Can we cover navigational perception needs of the visually impaired by panoptic segmentation?</a><br />
						In CoRR, 2020.
						<a class="b" href="https://arxiv.org/pdf/2007.10202">[PDF]</a>
						<b><a class="r" href="https://github.com/harvey-wei/Panoptic-Lintention-Net">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2020_omnisupervision_kailun.jpg" alt="">
					<p>
						<b>K. Yang</b>, X. Hu, K. Wang, R. Stiefelhagen.<br />
						<a class="db" href="https://ieeexplore.ieee.org/document/9304768/">In Defense of Multi-Source Omni-Supervised Efficient ConvNet for Robust Semantic Segmentation in Heterogeneous Unseen Domains.</a><br />
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Las Vegas, NV, United States (Virtual), October 2020.
						<a class="b" href="./publications/iv2020_omnisupervision_kailun.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/elnino9ykl/OmniSupervised-ConvNet">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2020_dspass_kailun.jpg" alt="">
					<p>
						<b>K. Yang</b>, X. Hu, H. Chen, K. Xiang, K. Wang, R. Stiefelhagen.<br />
						<a class="db" href="https://ieeexplore.ieee.org/document/9304706">DS-PASS: Detail-Sensitive Panoramic Annular Semantic Segmentation through SwaftNet for Surrounding Sensing.</a><br />
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Las Vegas, NV, United States (Virtual), October 2020.
						<a class="b" href="https://arxiv.org/pdf/1909.07721">[PDF]</a>
						<b><a class="r" href="https://youtu.be/pvhpxbdrA_4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/elnino9ykl/DS-PASS">[DATA+CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2020_yicheng.jpg" alt="">
					<p>
						Y. Fang, K. Wang, R. Cheng, <b>K. Yang</b>.<br />
						<a class="db" href="https://ieeexplore.ieee.org/document/9304612">CFVL: A Coarse-to-Fine Vehicle Localizer with Omnidirectional Perception across Severe Appearance Variations.</a><br />
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Las Vegas, NV, United States (Virtual), October 2020.
						<a class="b" href="http://wangkaiwei.org/file/publications/iv2020_yicheng.pdf">[PDF]</a>
						<a class="b" href="https://github.com/dachengzihhh/Chengyuan-dataset">[DATA]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/smc2020_yaozu.jpg" alt="">
					<p>
						Y. Ye, <b>K. Yang</b>, K. Xiang, J. Wang, K. Wang.<br />
						<a class="db" href="https://ieeexplore.ieee.org/document/9283099/">Universal Semantic Segmentation for Fisheye Urban Driving Images.</a><br />
						In IEEE International Conference on Systems, Man, and Cybernetics (<b>SMC</b>), Toronto, Canada (Virtual), October 2020.
						<a class="b" href="http://wangkaiwei.org/file/publications/smc2020_yaozu.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/Yaozhuwa/FisheyeSeg">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/itsc2020_keyang.jpg" alt="">
					<p>
						K. Zhou, K. Wang, <b>K. Yang</b>.<br />
						<a class="db" href="https://ieeexplore.ieee.org/document/9294206">PADENet: An Efficient and Robust Panoramic Monocular Depth Estimation Network for Outdoor Scenes.</a><br />
						In IEEE Intelligent Transportation Systems Conference (<b>ITSC</b>), Rhodes, Greece (Virtual), September 2020.
						<a class="b" href="http://wangkaiwei.org/file/publications/itsc2020_keyang.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/zzzkkkyyy/PADENet/tree/padenet-v1">[CODE]</a></b>
					</p>
				</div>
				
				<div class="dash">
					<img src="./images/icchp2020_haoye.jpg" alt="">
					<p>
						H. Chen, Y. Zhang, <b>K. Yang</b>, M. Martinez, K. Müller, R. Stiefelhagen.<br />
						<a class="db" href="https://link.springer.com/chapter/10.1007/978-3-030-58796-3_13">Can We Unify Perception and Localization in Assisted Navigation? An Indoor Semantic Visual Positioning System for Visually Impaired People.</a><br />
						In International Conference on Computers Helping People with Special Needs (<b>ICCHP</b>), Lecco, Italy (Virtual), September 2020.
						<a class="b" href="./publications/icchp2020_haoye.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/chyohoo/RFNet_SUNRGBD">[CODE]</a></b>
					</p>
				</div>

				<div class="dash">
					<img src="./images/cgiit2020_keyang.jpg" alt="">
					<p>
						K. Zhou, K. Wang, <b>K. Yang</b>.<br />
						<a class="db" href="https://iopscience.iop.org/article/10.1088/1742-6596/1518/1/012051">A Robust Monocular Depth Estimation Framework Based on Light-Weight ERF-PSPNet for Day-Night Driving Scenes.</a><br />
						In International Conference on Graphics, Images and Interactive Techniques (<b>CGIIT</b>), Sanya, China (Virtual), February 2020.
						<!--<a class="b" href="http://wangkaiwei.org/file/publications/cgiit2020_keyang.pdf">[PDF]</a>-->
						<a class="b" href="https://iopscience.iop.org/article/10.1088/1742-6596/1518/1/012051/pdf">[PDF]</a>
						<a class="b" href="https://github.com/elnino9ykl/ZJU-Dataset">[DATA]</a>
					</p>
				</div>
			</div>

			<h3 id="2019">
				2019
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">

				<div class="dash">
					<img src="./images/tits2019_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, X. Hu, L.M. Bergasa, E. Romera, K. Wang.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8835049">PASS:
							Panoramic Annular Semantic Segmentation.</a><br>
						<b>IEEE Transactions on Intelligent Transportation Systems</b>, 2019.
						<a class="b"
						   href="http://www.robesafe.uah.es/personal/bergasa/papers/IEEE_T_ITS_Kailun_2019_FINAL%20VERSION.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/elnino9ykl/PASS">[DATA+CODE]</a></b>

					</p>
				</div>

				<div class="dash">
					<img src="./images/ao2019_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, L.M. Bergasa, E. Romera, K. Wang.<br>
						<a class="db" href="https://www.osapublishing.org/ao/abstract.cfm?uri=ao-58-12-3141">Robustifying
							Semantic Cognition of Traversability across Wearable RGB-Depth Cameras.</a><br>
						<b>Applied Optics</b>, 2019.
						<b><a style="color:orangered">[Highlighted as an Editors' Pick]</a></b>
						<a class="b" href="http://wangkaiwei.org/file/publications/ao2019_kailun.pdf">[PDF]</a>
						<a class="b" href="https://github.com/elnino9ykl/SS4Blind">[DATA1]</a>
						<a class="b" href="http://wangkaiwei.org/file/RGB-D-SS%20Dataset.zip">[DATA2]</a>
						<b><a class="r" href="https://github.com/elnino9ykl/ERF-PSPNet">[CODE]</a></b>

					</p>
				</div>

				<div class="dash">
					<img src="./images/mst2019_weijian.jpg" alt="">
					<p>

						W. Hu, K. Wang, H. Chen, R. Cheng, <b>K. Yang</b>.<br>
						<a style="color:Midnightblue"
						   href="https://iopscience.iop.org/article/10.1088/1361-6501/ab40d9">An Indoor Positioning
							Framework Based on Panoramic Visual Odometry for Visually Impaired People.</a><br>
						<b>Measurement Science and Technology</b>, 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/mst2019_weijian.pdf">[PDF]</a>
						<b><a class="r" href="https://github.com/Huweijian/DSO-PAL">[CODE]</a></b>

					</p>
				</div>

				<div class="dash">
					<img src="./images/oe2019_hao.jpg" alt="">
					<p>

						H. Chen, K. Wang, W. Hu, <b>K. Yang</b>, R. Cheng, J. Bai.<br>
						<a style="color:Midnightblue"
						   href="https://www.osapublishing.org/oe/abstract.cfm?uri=oe-27-17-24481">PALVO: Visual
							odometry based on panoramic annular lens.</a><br>
						<b>Optics Express</b>, 2019.
						<a class="b" href="https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-27-17-24481">[HTML]</a>
						<a class="b" href="http://wangkaiwei.org/file/publications/oe2019_hao.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/ao2019_huabing.jpg" alt="">
					<p>

						H. Li, K. Wang, <b>K. Yang</b>, R. Cheng, C. Wang, L. Fei.<br>
						<a style="color:Midnightblue"
						   href="https://www.osapublishing.org/ao/abstract.cfm?uri=ao-58-23-6377">Unconstrained
							Self-Calibration of Stereo Camera on Visually Impaired Assistance Devices.</a><br>
						<b>Applied Optics</b>, 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/ao2019_huabing.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/rsi2019_ningbo.jpg" alt="">
					<p>

						N. Long, K. Wang, R. Cheng, W. Hu, <b>K. Yang</b>.<br>
						<a class="db" href="https://aip.scitation.org/doi/abs/10.1063/1.5093279">Unifying Obstacle
							Detection,
							Recognition and Fusion Based on Millimeter Wave Radar and RGB-Depth Sensors for the
							Visually Impaired.</a><br>
						<b>Review of Scientific Instruments</b>, 2019.
						<a class="b" href="https://aip.scitation.org/doi/full/10.1063/1.5093279">[HTML]</a>
						<a class="b" href="http://wangkaiwei.org/file/publications/rsi2019_ningbo.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/jei2019_ningbo.jpg" alt="">
					<p>

						N. Long, K. Wang, R. Cheng, <b>K. Yang</b>, W. Hu, J. Bai.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging/volume-28/issue-1/013028/Assisting-the-visually-impaired--multitarget-warning-through-millimeter-wave/10.1117/1.JEI.28.1.013028.short?SSO=1">Assisting
							the visually impaired: Multi-target warning through millimeter wave radar and RGB-depth
							sensors.</a><br>
						<b>Journal of Electronic Imaging</b>, 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/jei2019_ningbo.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/itsc2019_kaite.jpg" alt="">
					<p>

						K. Xiang, K. Wang, <b>K. Yang</b>.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8917096/">Importance-Aware Semantic
							Segmentation with Efficient Pyramidal Context Network for Navigational Assistant
							Systems.</a><br>
						In IEEE Intelligent Transportation Systems Conference (<b>ITSC</b>), Auckland, New Zealand,
						October 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/itsc2019_kaite.pdf">[PDF]</a>
						<a class="b" href="https://arxiv.org/abs/1907.11066">[arxiv]</a>
						<b><a class="r" href="https://github.com/Katexiang/ERF-PSPNET">[CODE]</a></b>

					</p>
				</div>

				<div class="dash">
					<img src="./images/itsc2019_ruiqi.jpg" alt="">
					<p>

						R. Cheng, K. Wang, S. Lin, W. Hu, <b>K. Yang</b>, X. Huang, H. Li, D. Sun, J. Bai.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8917508/">Panoramic
							Annular Localizer: Tackling the Variation Challenges of Outdoor Localization Using
							Panoramic Annular Images and Active Deep Descriptors.</a><br>
						In IEEE Intelligent Transportation Systems Conference (<b>ITSC</b>), Auckland, New Zealand,
						October 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/itsc2019_ruiqi.pdf">[PDF]</a>
						<a class="b" href="https://arxiv.org/abs/1905.05425.pdf">[arxiv]</a>
						<b><a class="r" href="https://github.com/chengricky/PAL">[DATA+CODE]</a></b>

					</p>
				</div>

				<div class="dash">
					<img src="./images/icip2019_xinxin.jpg" alt="">
					<p>

						X. Hu, <b>K. Yang</b>, L. Fei, K. Wang.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8803025">ACNet:
							Attention Based Network to Exploit Complementary Features for RGBD Semantic
							Segmentation.</a><br>
						In IEEE International Conference on Image Processing (<b>ICIP</b>), Taipei, China, September
						2019.
						<b><a href="https://scholar.google.com/citations?hl=en&amp;view_op=list_hcore&amp;venue=a9ZSGA40nccJ.2021&amp;vq=eng_computervisionpatternrecognition&amp;cstart=40"
							  style="color:orangered">[Main Publication in Google Scholar Metrics]</a></b>
						<a class="b" href="http://wangkaiwei.org/file/publications/icip2019_xinxin.pdf">[PDF]</a>
						<a class="b" href="https://arxiv.org/abs/1905.10089">[arxiv]</a>
						<b><a class="r" href="https://github.com/anheidelonghu/ACNet">[CODE]</a></b>
						<a class="b" href="https://mp.weixin.qq.com/s/S1xMR5L5KtyHZgW_lAdDDA">[PaperWeekly]</a>
						<a class="b" href="https://zhuanlan.zhihu.com/p/82193530">[ZhiHu]</a>
						<a class="b" href="http://wangkaiwei.org/blog/20190922/20190922.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2019_dongming.jpg" alt="">
					<p>

						D. Sun, X. Huang, <b>K. Yang</b>.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11166/111660L/A-multimodal-vision-sensor-for-autonomous-driving/10.1117/12.2535552.short">A
							Multimodal Vision Sensor for Autonomous Driving.</a><br>
						In SPIE Security + Defence Symposium, Strasbourg, France, September 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/spie2019_dongming.pdf">[PDF]</a>
						<a class="b" href="https://arxiv.org/abs/1908.05649">[arxiv]</a>
						<a class="b"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11166/111660L/A-multimodal-vision-sensor-for-autonomous-driving/10.1117/12.2535552.short">[Presentation]</a>
						<b><a class="r" href="https://github.com/dongmingsun/tx2-erfpsp">[CODE]</a></b>
						<a class="b" href="http://wangkaiwei.org/blog/20190909/20190909eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2019_kaite.jpg" alt="">
					<p>

						K. Xiang, K. Wang, <b>K. Yang</b>.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11169/111690C/A-comparative-study-of-high-recall-real-time-semantic-segmentation/10.1117/12.2532697.short">A
							Comparative Study of High-Recall Real-Time Semantic Segmentation Based on Swift
							Factorized Network.</a><br>
						In SPIE Security + Defence Symposium, Strasbourg, France, September 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/spie2019_kaite.pdf">[PDF]</a>
						<a class="b" href="https://arxiv.org/abs/1907.11394">[arxiv]</a>
						<a class="b"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11169/111690C/A-comparative-study-of-high-recall-real-time-semantic-segmentation/10.1117/12.2532697.short">[Presentation]</a>
						<b><a class="r"
							  href="https://github.com/Katexiang/swiftnet/tree/master/Swift_Factorized_Network(SFN)">[CODE]</a></b>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2019_jing.jpg" alt="">
					<p>

						J. Wang, J. Bai, X. Huang, X. Zhou, L. Zhao, K. Yan, J. Hou, <b>K. Yang</b>.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11169/111690H/Transparent-object-sensing-with-enhanced-prior-from-deep-convolutional-neural/10.1117/12.2533173.short">Transparent
							object sensing with enhanced prior from deep convolutional neural network.</a><br>
						In SPIE Security + Defence Symposium, Strasbourg, France, September 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/spie2019_jing.pdf">[PDF]</a>
						<a class="b"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11169/111690H/Transparent-object-sensing-with-enhanced-prior-from-deep-convolutional-neural/10.1117/12.2533173.short">[Presentation]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2019_yuanyou.jpg" alt="">
					<p>

						Y. Xu, K. Wang, <b>K. Yang</b>, D. Sun, J. Fu.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11169/111690B/Semantic-segmentation-of-panoramic-images-using-a-synthetic-dataset/10.1117/12.2532494.short">Semantic
							Segmentation of Panoramic Images Using a Synthetic Dataset.</a><br>
						In SPIE Security + Defence Symposium, Strasbourg, France, September 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/spie2019_yuanyou.pdf">[PDF]</a>
						<a class="b" href="https://arxiv.org/abs/1909.00532">[arxiv]</a>
						<a class="b"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11169/111690B/Semantic-segmentation-of-panoramic-images-using-a-synthetic-dataset/10.1117/12.2532494.short">[Presentation]</a>
						<b><a class="r" href="https://www.youtube.com/watch?v=--Mhldpd6nI">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/Francis515/SYNTHIA-PANO">[DATA+CODE]</a></b>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2019_chengyou.jpg" alt="">
					<p>

						C. Xu, K. Wang, <b>K. Yang</b>, R. Cheng, J. Bai.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11169/111690Q/Semantic-scene-understanding-on-mobile-device-with-illumination-invariance-for/10.1117/12.2532550.short">Semantic
							scene understanding on mobile device with illumination invariance for the visually
							impaired.</a><br>
						In SPIE Security + Defence Symposium, Strasbourg, France, September 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/spie2019_chengyou.pdf">[PDF]</a>
						<a class="b" href="https://github.com/elnino9ykl/SS4Blind">[DATA]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2019_lei.jpg" alt="">
					<p>

						L. Sun, K. Wang, <b>K. Yang</b>, K. Xiang.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11169/111690A/See-clearer-at-night--towards-robust-nighttime-semantic-segmentation/10.1117/12.2532477.short">See
							Clearer at Night: Towards Robust Nighttime Semantic Segmentation through Day-Night Image
							Conversion.</a><br>
						In SPIE Security + Defence Symposium, Strasbourg, France, September 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/spie2019_lei.pdf">[PDF]</a>
						<a class="b" href="https://arxiv.org/abs/1908.05868">[arxiv]</a>
						<a class="b"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11169/111690A/See-clearer-at-night--towards-robust-nighttime-semantic-segmentation/10.1117/12.2532477.short">[Presentation]</a>
						<a class="b" href="https://github.com/elnino9ykl/ZJU-Dataset">[DATA]</a>
						<b><a class="r" href="https://github.com/elnino9ykl/ERF-PSPNet">[CODE]</a></b>
						<a class="b" href="https://mp.weixin.qq.com/s/KfH8Uobcz8qL3E_KO9Ol5Q">[AITechTalk]</a>
						<a class="b" href="https://zhuanlan.zhihu.com/p/90297928">[ZhiHu]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2019_yicheng.jpg" alt="">
					<p>

						Y. Fang, K. Wang, R. Cheng, <b>K. Yang</b>, J. Bai.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11158/1115808/Visual-place-recognition-based-on-multilevel-descriptors-for-the-visually/10.1117/12.2532524.short">Visual
							place recognition based on multi-level descriptors for the visually impaired
							people.</a><br>
						In SPIE Security + Defence Symposium, Strasbourg, France, September 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/spie2019_yicheng.pdf">[PDF]</a>
						<a class="b"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11158/1115808/Visual-place-recognition-based-on-multilevel-descriptors-for-the-visually/10.1117/12.2532524.short">[Presentation]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2019_jiafeng.jpg" alt="">
					<p>

						J. Shen, K. Wang, <b>K. Yang</b>, K. Xiang, L. Fei, X. Hu, H. Li and H. Chen.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11158/1115807/A-depth-estimation-framework-based-on-unsupervised-learning-and-cross/10.1117/12.2532666.short">A
							Depth Estimation Framework Based on Unsupervised Learning and Cross-Modal
							Translation.</a><br>
						In SPIE Security + Defence Symposium, Strasbourg, France, September 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/spie2019_jiafeng.pdf">[PDF]</a>
						<a class="b"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11158/1115807/A-depth-estimation-framework-based-on-unsupervised-learning-and-cross/10.1117/12.2532666.short">[Presentation]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2019_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, X. Hu, L.M. Bergasa, E. Romera, X. Huang, D. Sun, K. Wang.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8814042">Can we
							PASS beyond the Field of View? Panoramic Annular Semantic Segmentation for Real-World
							Surrounding Perception.</a><br>
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Paris, France, June 2019.
						<a class="b"
						   href="http://www.robesafe.uah.es/personal/bergasa/papers/IV2019_Kailun.pdf">[PDF]</a>
						<b><a class="r" href="http://www.robesafe.uah.es/personal/bergasa/papers/IV2019_1384x3432.mp4">[VIDEO]</a></b>
						<b><a class="r" href="https://github.com/elnino9ykl/PASS">[DATA+CODE]</a></b>
						<a class="b" href="http://wangkaiwei.org/blog/20190609/20190609eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2019_eduardo.jpg" alt="">
					<p>

						E. Romera, L.M. Bergasa, <b>K. Yang</b>, J.M. Álvarez, R. Barea.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8813888/">Bridging
							the Day and Night Domain Gap for Semantic Segmentation.</a><br>
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Paris, France, June 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/iv2019_eduardo.pdf">[PDF]</a>
						<a class="b" href="https://github.com/elnino9ykl/ZJU-Dataset">[DATA]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/cgiit2019_kaite.jpg" alt="">
					<p>

						K. Xiang, K. Wang, L. Fei, <b>K. Yang</b>.<br>
						<a class="db" href="https://iopscience.iop.org/article/10.1088/1742-6596/1229/1/012070">Store
							Sign
							Text Recognition for Wearable Navigation Assistance System.</a><br>
						In International Conference on Graphics, Images and Interactive Techniques (<b>CGIIT</b>),
						Guangzhou, China, February 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/cgiit2019_kaite.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/blog/20190222/20190222eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/cgiit2019_yaozu.jpg" alt="">
					<p>

						Y. Ye, K. Wang, W. Hu, H. Li, <b>K. Yang</b>, L. Sun, Z. Chen.<br>
						<a class="db" href="https://iopscience.iop.org/article/10.1088/1742-6596/1229/1/012026">A
							Wearable
							Vision-To-Audio Sensory Substitution Device for Blind Assistance and the Correlated
							Neural Substrates.</a><br>
						In International Conference on Graphics, Images and Interactive Techniques (<b>CGIIT</b>),
						Guangzhou, China, February 2019.
						<a class="b" href="http://wangkaiwei.org/file/publications/cgiit2019_yaozu.pdf">[PDF]</a>

					</p>
				</div>
			</div>

			<h3 id="2018">
				2018
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">

				<div class="dash">
					<img src="./images/sensors2018_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, K. Wang, L.M. Bergasa, E. Romera, W. Hu, D. Sun, J. Sun, R. Cheng, T. Chen,
						E. López.<br>
						<a class="db" href="http://www.mdpi.com/1424-8220/18/5/1506">Unifying
							Terrain Awareness for the Visually Impaired through Real-Time Semantic
							Segmentation.</a><br>
						<b>Sensors</b>, 2018.
						<span>Belongs to the Special Issue<span>
						<a class="b" href="http://www.mdpi.com/journal/sensors/special_issues/smart_wearable">[Wearable
							Smart
							Devices]</a>
						<a style="color:BLUE" href="http://www.mdpi.com/1424-8220/18/5/1506/htm">[HTML]</a>
						<a class="b" href="http://www.mdpi.com/1424-8220/18/5/1506/pdf">[PDF]</a>
						<a class="b" href="https://github.com/elnino9ykl/SS4Blind">[DATA1]</a>
						<a class="b" href="http://wangkaiwei.org/file/terrain%20awareness%20dataset.zip">[DATA2]</a>
						<b><a class="r" href="https://github.com/Katexiang/ERF-PSPNET">[TensorFlow]</a></b>
						<b><a class="r" href="https://github.com/elnino9ykl/ERF-PSPNet">[PyTorch]</a></b>
						<b><a style="color:orangered" href="https://github.com/dongmingsun/tx2-erfpsp">[NVIDIA
							TX1/TX2 Implementation]</a></b>

					</span></span></p>
				</div>

				<div class="dash">
					<img src="./images/ao2018_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, K. Wang, H. Chen, J. Bai.<br>
						<a class="db" href="https://www.osapublishing.org/ao/abstract.cfm?uri=ao-57-11-2809">Reducing
							the
							minimum range of a RGB-depth sensor to aid navigation in visually impaired
							individuals.</a><br>
						<b>Applied Optics</b>, 2018.
						<b><a style="color:orangered">[Highlighted as an Editors' Pick]</a></b>
						<a class="b" href="http://wangkaiwei.org/file/publications/ao2018_kailun.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/sensors2018_shufeiruiqi.jpg" alt="">
					<p>

						S. Lin, R. Cheng, K. Wang, <b>K. Yang</b>.<br>
						<a class="db" href="http://www.mdpi.com/1424-8220/18/8/2476/">Visual
							Localizer: Outdoor Localization Based on ConvNet Descriptor and Global Optimization for
							Visually Impaired Pedestrians.</a><br>
						<b>Sensors</b>, 2018.
						<span>Belongs to the Special Issue<span>
						<a class="b"
						   href="https://www.mdpi.com/journal/sensors/special_issues/Sensor_Caring_People_with_Disabilities">[Sensor
							Technologies for Caring People with Disabilities]</a>
						<a style="color:BLUE" href="http://www.mdpi.com/1424-8220/18/8/2476/htm">[HTML]</a>
						<a class="b" href="http://www.mdpi.com/1424-8220/18/8/2476/pdf">[PDF]</a>
						<a class="b" href="https://www.researchgate.net/publication/327360664_Supplementary_Material">[DATA]</a>

					</span></span></p>
				</div>

				<div class="dash">
					<img src="./images/mta2018_ruiqi.jpg" alt="">
					<p>

						R. Cheng, K. Wang, <b>K. Yang</b>, N. Long, J. Bai, D. Liu.<br>
						<a class="db" href="https://link.springer.com/article/10.1007/s11042-017-5472-5">Real-time
							pedestrian
							crossing lights detection algorithm for the visually impaired.</a><br>
						<b>Multimedia Tools and Applications</b>, 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/mta2018_ruiqi.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/file/PTLR%20dataset.rar">[DATA]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/robio2018_kailunruiqi.jpg" alt="">
					<p>

						<b>K. Yang</b>, R. Cheng, L.M. Bergasa, E. Romera, K. Wang, N. Long.<br>
						<a class="db" href="https://ieeexplore.ieee.org/abstract/document/8665211">Intersection
							perception
							through real-time semantic segmentation to assist navigation of visually impaired
							pedestrians.</a><br>
						In IEEE International Conference on Robotics and Biomimetics (<b>ROBIO</b>), Kuala Lumpur,
						Malaysia, December 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/robio2018_kailunruiqi.pdf">[PDF]</a>
						<a class="b" href="https://github.com/elnino9ykl/SS4Blind">[DATA1]</a>
						<a class="b"
						   href="http://wangkaiwei.org/file/Crosswalk%20Pixelwise%20Groundtruth.zip">[DATA2]</a>
						<a class="b" href="http://www.wangkaiwei.org/blog/20181212/20181212eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/robio2018_kailunjuan.jpg" alt="">
					<p>

						<b>K. Yang</b>, L.M. Bergasa, E. Romera, J. Wang, K. Wang, E. López.<br>
						<a class="db" href="https://ieeexplore.ieee.org/abstract/document/8664804">Perception
							framework of
							water hazards beyond traversability for real-world navigation assistance
							systems.</a><br>
						In IEEE International Conference on Robotics and Biomimetics (<b>ROBIO</b>), Kuala Lumpur,
						Malaysia, December 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/robio2018_kailunjuan.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/file/pRGB-D%20dataset.rar">[DATA]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/humanoids2018_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, L.M. Bergasa, E. Romera, X. Huang, K. Wang.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8625005">Predicting
							polarization beyond semantics for wearable robotics.</a><br>
						In IEEE-RAS International Conference on Humanoid Robots (<b>Humanoids</b>), Beijing, China,
						November 2018.
						<b><a style="color:orangered">[Spotlight Paper]</a></b>
						<a class="b" href="http://wangkaiwei.org/file/publications/humanoids2018_kailun.pdf">[PDF]</a>
						<a class="b"
						   href="http://wangkaiwei.org/file/Polarization%20Prediction%20Dataset.rar">[DATA]</a>
						<b><a class="r" href="https://github.com/elnino9ykl/ERF-PSPNet">[PyTorch]</a></b>
						<a class="b" href="http://wangkaiwei.org/blog/20181110/20181110eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/smc2018_juan.jpg" alt="">
					<p>

						J. Wang, <b>K. Yang</b>, W. Hu, K. Wang.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8616328/">An
							environmental perception and navigational assistance system for visually impaired
							persons based on semantic stixels and sound interaction.</a><br>
						In IEEE International Conference on Systems, Man, and Cybernetics (<b>SMC</b>), Miyazaki,
						Japan, October 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/smc2018_juan.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/blog/20181012/20181012eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/irc2018_ningbo.jpg" alt="">
					<p>

						N. Long, K. Wang, R. Cheng, W. Hu, <b>K. Yang</b>.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8878280">Low Power
							Millimeter Wave Radar System for the Visually Impaired.</a><br>
						In IET International Radar Conference (<b>IRC</b>), Nanjing, China, October 2018.
						<b><a style="color:orangered">[Excellent Paper Award]</a></b>
						<a class="b" href="http://wangkaiwei.org/file/publications/irc2018_ningbo.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/blog/20180825/20180825eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/wps2018_yaozu.jpg" alt="">
					<p>

						Y. Ye, K. Wang, W. Hu, <b>K. Yang</b>.<br>
						<span>Study on the brain mechanisum in visual assistance for the
							blind.</span><br>
						In West-Lake Photonics Symposium (<b>WPS</b>), Hangzhou, China, October 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/wps2018_yaozu.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/wps2018_zhiming.jpg" alt="">
					<p>

						Z. Huang, K. Wang, <b>K. Yang</b>, R. Cheng, J. Bai.<br>
						<span>Glass detection and recognition based on the fusion of
							ultrasonic sensor and RGB-D sensor for the visually impaired.</span><br>
						In West-Lake Photonics Symposium (<b>WPS</b>), Hangzhou, China, October 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/wps2018_zhiming.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/wps2018_ningbo.jpg" alt="">
					<p>

						N. Long, K. Wang, R. Cheng, <b>K. Yang</b>, W. Hu, J. Bai.<br>
						<span>Mutiple Target Warning through Millimeter Wave Radar and
							RGB-Depth Sensors.</span><br>
						In West-Lake Photonics Symposium (<b>WPS</b>), Hangzhou, China, October 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/wps2018_ningbo.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/icves2018_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, L.M. Bergasa, E. Romera, D. Sun, K. Wang, R. Barea.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8519526">Semantic
							perception of curbs beyond traversability for real-world navigation assistance
							systems.</a><br>
						In IEEE International Conference on Vehicular Electronics and Safety (<b>ICVES</b>), Madrid,
						Spain, September 2018.
						<a class="b" href="http://www.robesafe.uah.es/personal/bergasa/papers/icves2018.pdf">[PDF]</a>
						<a class="b" href="https://github.com/elnino9ykl/SS4Blind">[DATA1]</a>
						<a class="b" href="http://wangkaiwei.org/file/Curbs%20Dataset.zip">[DATA2]</a>
						<a class="b" href="http://wangkaiwei.org/blog/20180914/20180914eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2018_lei.jpg" alt="">
					<p>

						L. Fei, K. Wang, S. Lin, <b>K. Yang</b>, R. Cheng and H. Chen.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10794/107940S/Scene-text-detection-and-recognition-system-for-visually-impaired-people/10.1117/12.2325523.short">Scene
							text detection and recognition system for visually impaired people in real
							world.</a><br>
						In SPIE Security + Defence Symposium, Berlin, Germany, September 2018.
						<b><a style="color:orangered">[Best Student Paper]</a></b>
						<a class="b"
						   href="http://wangkaiwei.org/file/publications/securitydefence2018_lei.pdf">[PDF]</a>
						<a class="b"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10794/107940S/Scene-text-detection-and-recognition-system-for-visually-impaired-people/10.1117/12.2325523.short">[Presentation]</a>
						<a class="b" href="http://wangkaiwei.org/blog/20180915/20180915eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2018_ningbo.jpg" alt="">
					<p>

						N. Long, K. Wang, R. Cheng, <b>K. Yang</b>, J. Bai.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10800/1080006/Fusion-of-millimeter-wave-radar-and-RGB-depth-sensors-for/10.1117/12.2324626.short">Fusion
							of Millimeter wave Radar and RGB-Depth sensors for assisted navigation of the visually
							impaired.</a><br>
						In SPIE Security + Defence Symposium, Berlin, Germany, September 2018.
						<a class="b"
						   href="http://wangkaiwei.org/file/publications/securitydefence2018_ningbo.pdf">[PDF]</a>
						<a class="b"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10800/1080006/Fusion-of-millimeter-wave-radar-and-RGB-depth-sensors-for/10.1117/12.2324626.short">[Presentation]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/spie2018_zhiming.jpg" alt="">
					<p>

						Z. Huang, K. Wang, <b>K. Yang</b>, R. Cheng, J. Bai.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10794/107940F/Glass-detection-and-recognition-based-on-the-fusion-of-ultrasonic/10.1117/12.2325496.short">Glass
							Detection and Recognition Based on the Fusion of Ultrasonic Sensor and RGB-D Sensor for
							the Visually Impaired.</a><br>
						In SPIE Security + Defence Symposium, Berlin, Germany, September 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/securitydefence2018_zhiming.pdf">[PDF]</a>
						<a class="b"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10794/107940F/Glass-detection-and-recognition-based-on-the-fusion-of-ultrasonic/10.1117/12.2325496.short">[Presentation]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/icpr2018_ruiqi.jpg" alt="">
					<p>

						R. Cheng, K. Wang, L. Lin, <b>K. Yang</b>.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8545141">Visual
							Localization of Key Positions for Visually Impaired People.</a><br>
						In International Conference on Pattern Recognition (<b>ICPR</b>), Beijing, China, August
						2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/icpr2018_ruiqi.pdf">[PDF]</a>
						<a class="b" href="https://arxiv.org/abs/1810.03790">[arxiv]</a>
						<a class="b" href="http://wangkaiwei.org/file/VLdataset.rar">[DATA]</a>
						<b><a class="r" href="https://github.com/chengricky/OpenMultiPR">[CODE]</a></b>
						<a class="b" href="http://wangkaiwei.org/blog/20180824/20180824eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/icchp2018_shufei.jpg" alt="">
					<p>

						S. Lin, K. Wang, <b>K. Yang</b>, R. Cheng.<br>
						<a class="db" href="https://link.springer.com/chapter/10.1007/978-3-319-94274-2_9">KrNet: A
							Kinetic
							Real-time Convolutional Neural Network for Navigational Assistance.</a><br>
						In International Conference on Computers Helping People with Special Needs (<b>ICCHP</b>),
						Linz, Austria, July 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/icchp2018_shufei.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/blog/20180715/20180715eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/iv2018_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, L.M. Bergasa, E. Romera, R. Cheng, T. Chen, K. Wang.<br>
						<a class="db" href="https://ieeexplore.ieee.org/document/8500506">Unifying
							terrain awareness through real-time semantic segmentation.</a><br>
						In IEEE Intelligent Vehicles Symposium (<b>IV</b>), Suzhou, China, June 2018.
						<b><a href="https://scholar.google.com/citations?hl=en&amp;view_op=list_hcore&amp;venue=BXKrKfEyuD0J.2020&amp;vq=eng_transportation&amp;cstart=20"
							  style="color:orangered">[Main Publication in Google Scholar Metrics]</a></b>
						<a class="b" href="http://www.robesafe.es/personal/bergasa/papers/iv2018_kailun.pdf">[PDF]</a>
						<b><a class="r" href="http://www.robesafe.es/personal/bergasa/videos/Video.mp4">[VIDEO]</a></b>
						<a class="b" href="https://github.com/elnino9ykl/SS4Blind">[DATA1]</a>
						<a class="b" href="http://wangkaiwei.org/file/terrain%20awareness%20dataset.zip">[DATA2]</a>
						<b><a class="r" href="https://github.com/Katexiang/ERF-PSPNET">[TensorFlow]</a></b>
						<b><a class="r" href="https://github.com/elnino9ykl/ERF-PSPNet">[PyTorch]</a></b>
						<a class="b" href="http://wangkaiwei.org/blog/20180630/20180630eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/iciss2018_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, K. Wang, S. Lin, J. Bai, L.M. Bergasa, R. Arroyo.<br>
						<a class="db" href="https://dl.acm.org/citation.cfm?id=3209943">Long-range
							Traversability Awareness and Low-lying Obstacle Negotiation with RealSense for the
							Visually Impaired.</a><br>
						In International Conference on Information Science and System (<b>ICISS</b>), Jeju Island,
						South Korea, April 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/iciss2018_kailun.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/iciss2018_hao.jpg" alt="">
					<p>

						H. Chen, K. Wang, <b>K. Yang</b>.<br>
						<a class="db" href="https://dl.acm.org/citation.cfm?id=3209944">Improving
							RealSense by Fusing Color Stereo Vision and Infrared Stereo Vision for the Visually
							Impaired.</a><br>
						In International Conference on Information Science and System (<b>ICISS</b>), Jeju Island,
						South Korea, April 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/iciss2018_hao.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/icfip2018_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, K. Wang, S. Lin, J. Bai, L.M. Bergasa, R. Arroyo.<br>
						<span>Long-range Traversability Awareness and Low-lying Obstacle
							Negotiation with RealSense for the Visually Impaired.</span><br>
						In International Conference on Frontiers of Image Processing (<b>ICFIP</b>), Barcelona,
						Spain, March 2018.
						<b><a style="color:orangered"
							  href="http://www.robesafe.uah.es/personal/bergasa/papers/Kailun_BestPaperAward.pdf">[Best
							Paper Award]</a></b>
						<a class="b" href="http://www.robesafe.uah.es/personal/bergasa/papers/ICFIP2018_Kailun.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/blog/20180311/20180311eg.html">[BLOG]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/icfip2018_hao.jpg" alt="">
					<p>

						H. Chen, K. Wang, <b>K. Yang</b>.<br>
						<span>Improving RealSense by Fusing Color Stereo Vision and Infrared
							Stereo Vision for the Visually Impaired.</span><br>
						In International Conference on Frontiers of Image Processing (<b>ICFIP</b>), Barcelona,
						Spain, March 2018.
						<a class="b" href="http://wangkaiwei.org/file/publications/icfip2018_hao.pdf">[PDF]</a>

					</p>
				</div>
			</div>

			<h3 id="2017">
				2017
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">

				<div class="dash">
					<img src="./images/sensors2017_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, K. Wang, R. Cheng, W. Hu, X. Huang, J. Bai.<br>
						<a class="db" href="http://www.mdpi.com/1424-8220/17/8/1890">Detecting
							Traversable Area and Water Hazards for the Visually Impaired with a pRGB-D
							Sensor.</a><br>
						<b>Sensors</b>, 2017.
						<a class="b" href="http://www.mdpi.com/1424-8220/17/8/1890/htm">[HTML]</a>
						<a class="b" href="http://www.mdpi.com/1424-8220/17/8/1890/pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/file/pRGB-D%20dataset.rar">[DATA]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/jaise2017_kailun.jpg" alt="">
					<p>

						<b>K. Yang</b>, K. Wang, X. Zhao, R. Cheng, J. Bai, Y. Yang, D. Liu.<br>
						<a class="db"
						   href="https://content.iospress.com/articles/journal-of-ambient-intelligence-and-smart-environments/ais459">IR
							stereo RealSense: Decreasing minimum range of navigational assistance for visually
							impaired individuals.</a><br>
						<b>Journal of Ambient Intelligence and Smart Environments</b>, 2017.
						<a class="b" href="http://wangkaiwei.org/file/publications/jaise2017_kailun.pdf">[PDF]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/jei2017_ruiqi.jpg" alt="">
					<p>

						R. Cheng, K. Wang, <b>K. Yang</b>, N. Long, W. Hu, H. Chen, J. Bai, D. Liu.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging/volume-26/issue-5/053025/Crosswalk-navigation-for-people-with-visual-impairments-on-a-wearable/10.1117/1.JEI.26.5.053025.short?SSO=1">Crosswalk
							navigation for people with visual impairments on a wearable device.</a><br>
						<b>Journal of Electronic Imaging</b>, 2017.
						<a class="b" href="http://wangkaiwei.org/file/publications/jei2017_ruiqi.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/file/crosswalk%20DATASET.rar">[DATA1]</a>
						<a class="b" href="https://github.com/elnino9ykl/SS4Blind">[DATA2]</a>

					</p>
				</div>

				<div class="dash">
					<img src="./images/oe2016_xiao.jpg" alt="">
					<p>

						X. Huang, J. Bai, K. Wang, Q. Liu, Y. Luo, <b>K. Yang</b>, X. Zhang.<br>
						<a class="db" href="https://www.osapublishing.org/oe/abstract.cfm?uri=oe-25-2-1173">Target
							enhanced 3D
							reconstruction based on polarization-coded structured light.</a><br>
						<b>Optics Express</b>, 2017.
						<a class="b"
						   href="https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-25-2-1173&amp;id=357437">[HTML]</a>
						<a class="b" href="http://wangkaiwei.org/file/publications/oe2017_xiao.pdf">[PDF]</a>

					</p>
				</div>
			</div>

			<h3 id="2016">
				2016
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">

				<div class="dash">
					<img src="./images/sensors2016_kailun.jpg" alt="">
					<p>
						<b>K. Yang</b>, K. Wang, W. Hu, J. Bai.<br>
						<a class="db" href="http://www.mdpi.com/1424-8220/16/11/1954">Expanding the
							Detection of Traversable Area with RealSense for the Visually Impaired.</a><br>
						<b>Sensors</b>, 2016.
						<a class="b" href="http://www.mdpi.com/1424-8220/16/11/1954/htm">[HTML]</a>
						<a class="b" href="http://www.mdpi.com/1424-8220/16/11/1954/pdf">[PDF]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icgip2016_xiangdong.jpg" alt="">
					<p>
						X. Zhao, K. Wang, <b>K. Yang</b>, W. Hu.<br>
						<a class="db"
						   href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10225/1022509/Unconstrained-face-detection-and-recognition-based-on-RGB-D-camera/10.1117/12.2266122.short">Unconstrained
							Face Detection and Recognition Based on RGB-D Camera for the Visually Impaired.</a><br>
						In International Conference on Graphic and Image Processing (<b>ICGIP</b>), Tokyo, Japan, August
						2016.
						<a class="b" href="http://wangkaiwei.org/file/publications/icgip2016_xiangdong.pdf">[PDF]</a>
					</p>
				</div>

			</div>

			<h3 id="2015">
				2015
				<a class="pub-fold" href="javascript:void(0)">折叠</a>
				<span class="pub-count"></span>
			</h3>

			<div class="dashset">

				<div class="dash">
					<img src="./images/icbisp2015_kailun.jpg" alt="">
					<p>
						<b>K. Yang</b>, K. Wang, R. Cheng, X. Zhu.<br>
						<a class="db" href="https://ieeexplore.ieee.org/abstract/document/7450354/">A
							new approach of point cloud processing and scene segmentation for guiding the visually
							impaired.</a><br>
						In IET International Conference on Biomedical Image and Signal Processing (<b>ICBISP</b>),
						Beijing, China, November 2015.
						<a class="b" href="http://wangkaiwei.org/file/publications/icbisp2015_kailun.pdf">[PDF]</a>
						<a class="b" href="http://wangkaiwei.org/blog/20151119/20151119eg.html">[BLOG]</a>
					</p>
				</div>

				<div class="dash">
					<img src="./images/icbisp2015_ruiqi.jpg" alt="">
					<p>
						R. Cheng, K. Wang, <b>K. Yang</b>, X. Zhao.<br>
						<a class="db" href="https://ieeexplore.ieee.org/abstract/document/7450353/">A
							Ground and Obstacle Detection Algorithm for the Visually Impaired.</a><br>
						In IET International Conference on Biomedical Image and Signal Processing (<b>ICBISP</b>),
						Beijing, China, November 2015.
						<a class="b" href="http://wangkaiwei.org/file/publications/icbisp2015_ruiqi.pdf">[PDF]</a>
					</p>
				</div>

			</div>
		</div>
	</div>

	<div id="backTop">回到<br>导航</div>
	<div id="toast">已复制</div>

	<script src="script/navbar.js"></script>
	<script src="script/index.js"></script>
</div>
</body>
</html>